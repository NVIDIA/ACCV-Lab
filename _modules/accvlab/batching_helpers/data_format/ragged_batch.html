

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>accvlab.batching_helpers.data_format.ragged_batch &mdash; ACCV-Lab 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css?v=9282052d" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            ACCV-Lab
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">General Info</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../project_overview/README.html">ACCV-Lab Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guides_index.html">Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contained Packages</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../contained_package_docs_mirror/on_demand_video_decoder/docs/index.html">On Demand Video Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contained_package_docs_mirror/batching_helpers/docs/index.html">Batching Helpers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contained_package_docs_mirror/dali_pipeline_framework/docs/index.html">DALI Pipeline Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contained_package_docs_mirror/draw_heatmap/docs/index.html">Draw Heatmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contained_package_docs_mirror/optim_test_tools/docs/index.html">Optimization Testing Tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">ACCV-Lab</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">accvlab.batching_helpers.data_format.ragged_batch</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for accvlab.batching_helpers.data_format.ragged_batch</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2025, NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Callable</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.set_padded_to</span><span class="w"> </span><span class="kn">import</span> <span class="n">SetPaddedTo</span>

<span class="c1"># Type aliases for processing function signatures and returns</span>
<span class="n">ReturnTensor</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span>
<span class="n">ProcStep</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">ReturnTensor</span><span class="p">],</span>
    <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">ReturnTensor</span><span class="p">],</span>
    <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">ReturnTensor</span><span class="p">],</span>
<span class="p">]</span>


<div class="viewcode-block" id="RaggedBatch">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RaggedBatch</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for representing batches with samples with variable size in one dimension.</span>

<span class="sd">    The representation of the batch contains 3 tensors:</span>
<span class="sd">        - tensor:</span>
<span class="sd">            This is the actual data. It has the size of the largest sample</span>
<span class="sd">            in the non-uniform dimension, and the other samples are padded on the &quot;right&quot; (i.e.</span>
<span class="sd">            at the end containing larger indices) with filler values to match the size of the largest sample.</span>
<span class="sd">            While the padding is typically initialized with 0, no values should be assumed for the</span>
<span class="sd">            padded region as the values there may change after operations are performed on the</span>
<span class="sd">            data. If the non-uniform dimension is `dim==num_batch_dims`, the shape is</span>
<span class="sd">            (\*batch_dims_shape, max_sample_size, \*data_shape). More generally, the first dimensions are the</span>
<span class="sd">            batch dimensions (one or more). The non-uniform dimension can be any dimension after the batch dimensions</span>
<span class="sd">            and the size of the non-uniform dimension always corresponds to the maximum sample</span>
<span class="sd">            size in the batch. The remaining dimensions correspond to the shape of the data, which can have</span>
<span class="sd">            any number of dimensions, including 0 (per-object scalar data).</span>
<span class="sd">        - mask:</span>
<span class="sd">            This is the mask indicating which elements are valid (`True`) and which are</span>
<span class="sd">            not (`False`). It has dimensions: (\*batch_dims_shape, max_sample_size).</span>
<span class="sd">            The dimension after the batch dimensions corresponds to the non-uniform dimension in the data</span>
<span class="sd">            tensor.</span>
<span class="sd">        - sample_sizes:</span>
<span class="sd">            Sizes of the individual samples, i.e. the actual sizes without padding along the</span>
<span class="sd">            non-uniform dimension.</span>
<span class="sd">            Shape: (\*batch_dims_shape,)</span>

<span class="sd">    Additional attributes describing the batch:</span>
<span class="sd">        - non_uniform_dim:</span>
<span class="sd">            Indicates which dimension is the non-uniform dimension</span>
<span class="sd">        - num_batch_dims:</span>
<span class="sd">            Number of batch dimensions at the beginning of the tensor</span>

<span class="sd">    Note:</span>
<span class="sd">        The tensors described above correspond to the :attr:`tensor`, :attr:`mask`, and :attr:`sample_sizes`</span>
<span class="sd">        attributes, respectively. The non-uniform dimension can be accessed as :attr:`non_uniform_dim` and the</span>
<span class="sd">        number of batch dimensions as :attr:`num_batch_dims`.</span>

<span class="sd">    Important:</span>
<span class="sd">        The :attr:`mask` and :attr:`non_uniform_dim` attributes may be shared between instances of</span>
<span class="sd">        :class:`RaggedBatch` instances with different data tensors, so they should be treated as</span>
<span class="sd">        constants and never be changed in-place.</span>

<span class="sd">    Example:</span>

<span class="sd">        Here, we show an example of a :class:`RaggedBatch` instance.</span>

<span class="sd">        In the image::</span>
<span class="sd">          - Letters indicate data entries that are valid (i.e. correspond to the actual data).</span>
<span class="sd">          - &#39;*&#39; indicates padded filler entries (i.e. invalid entries) in the data.</span>

<span class="sd">        .. image:: images/RaggedBatchExample.png</span>
<span class="sd">            :alt: Example of a RaggedBatch</span>
<span class="sd">            :align: center</span>

<span class="sd">        Note that:</span>
<span class="sd">          - The example shows a single batch dimension of size 4. More batch and data dimensions are supported.</span>
<span class="sd">          - The maximum sample size (i.e. the size of the non-uniform dimension) is 3.</span>
<span class="sd">          - Each element in :attr:`self.tensor` may represent a single value (corresponding to scalar data and 0 data dimensions),</span>
<span class="sd">            or itself represent a non-scalar entry (in case for one or more data dimensions).</span>
<span class="sd">          - Even if more data dimensions are present, the `mask` has always `num_batch_dims + 1` dimensions, as the data dimensions</span>
<span class="sd">            are not needed in the mask.</span>
<span class="sd">          - The `sample_sizes` have the same shape as the batch dimensions (i.e. `(4,)` in this example), as they contain one value per sample.</span>
<span class="sd">          - The `sample_sizes` and `mask` contain the same information. However</span>

<span class="sd">            - Dependent on the use case, one of them may be more efficient &amp; convenient to use</span>
<span class="sd">            - One can be efficiently computed from the other (as is done as needed in the `RaggedBatch` implementation).</span>

<span class="sd">    Note:</span>
<span class="sd">        The number of batch dimensions is determined from the shape of the provided `mask` or `sample_sizes` tensor.</span>

<span class="sd">    Warning:</span>
<span class="sd">        If both `mask` and `sample_sizes` are set, they need to be consistent with each other. This is</span>
<span class="sd">        not checked in the constructor. Inconsistent masks and sample sizes will lead to undefined behavior.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_CPU</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">non_uniform_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Args:</span>
<span class="sd">            tensor: Data to be stored (corresponding to the :attr:`tensor` tensor of :class:`RaggedBatch`, see description above)</span>
<span class="sd">            mask: Mask indicating which entries are valid (corresponding to the :attr:`mask` tensor of :class:`RaggedBatch`, see description above).</span>
<span class="sd">                If not set, `sample_sizes` is internally used to create a mask.</span>
<span class="sd">                Note that at least one of `mask` or `sample_sizes` needs to be set.</span>
<span class="sd">            sample_sizes: Number of valid entries for all samples (corresponding to the :attr:`sample_sizes` tensor of :class:`RaggedBatch`, see description above).</span>
<span class="sd">                If not set, `mask` is internally used to create a sample sizes tensor.</span>
<span class="sd">                Note that at least one of `mask` or `sample_sizes` needs to be set.</span>
<span class="sd">            non_uniform_dim: Dimension in which the batch is non-uniform, default: 1</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;At least one of `mask` or `sample_sizes` needs to be set&quot;</span>

        <span class="k">if</span> <span class="n">sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_batch_dims</span> <span class="o">=</span> <span class="n">sample_sizes</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_batch_dims</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="k">assert</span> <span class="n">num_batch_dims</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Number of batch dimensions needs to be greater than 0&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">num_batch_dims</span> <span class="o">&lt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="p">),</span> <span class="s2">&quot;The number of dimensions of the tensor needs to be at least num_batch_dims + 1&quot;</span>

        <span class="k">if</span> <span class="n">non_uniform_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">non_uniform_dim</span> <span class="o">=</span> <span class="n">num_batch_dims</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">non_uniform_dim</span> <span class="o">&gt;=</span> <span class="n">num_batch_dims</span> <span class="ow">and</span> <span class="n">non_uniform_dim</span> <span class="o">&lt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="p">),</span> <span class="s2">&quot;Non-uniform dimensions needs to be in the range [num_batch_dims; tensor.dim()[&quot;</span>

        <span class="k">assert</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span> <span class="o">==</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span>
            <span class="ow">and</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">num_batch_dims</span><span class="p">]</span> <span class="o">==</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">non_uniform_dim</span><span class="p">]</span>
        <span class="p">),</span> <span class="p">(</span>
            <span class="s2">&quot;Shape of `tensor` does not match the required shape:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  According to mask: Batch shape: </span><span class="si">{</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2">; Maximum sample size: </span><span class="si">{</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  According to tensor: Batch shape: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2">; Maximum sample size: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">non_uniform_dim</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="n">sample_sizes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="n">sample_sizes</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span> <span class="o">==</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span>
        <span class="p">),</span> <span class="p">(</span>
            <span class="s2">&quot;Batch shape according to `tensor` does not match the size of `sample_sizes`:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  According to tensor: Batch shape: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  According to sample_sizes: Batch shape: </span><span class="si">{</span><span class="n">sample_sizes</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span> <span class="o">=</span> <span class="n">tensor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="o">=</span> <span class="n">mask</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="o">=</span> <span class="n">sample_sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">=</span> <span class="n">non_uniform_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span> <span class="o">=</span> <span class="n">num_batch_dims</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_total_num_targets</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="RaggedBatch.FromOversizeTensor">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.FromOversizeTensor">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">FromOversizeTensor</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">non_uniform_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a :class:`RaggedBatch` instance from a tensor which is over-sized in the non-uniform dimension.</span>

<span class="sd">        Over-sized means that the non-uniform dimension is larger than the maximum sample size in the batch.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor: Data to be stored (corresponding to the :attr:`tensor` tensor of :class:`RaggedBatch`, see description above) except that the</span>
<span class="sd">                non-uniform dimension is larger than the maximum sample size in the batch.</span>
<span class="sd">                The tensor in the is truncated to the maximum sample size in the batch.</span>
<span class="sd">            mask: Mask indicating which entries are valid (corresponding to the :attr:`mask` tensor of :class:`RaggedBatch`, see description above).</span>
<span class="sd">                If not set, `sample_sizes` is internally used to create a mask.</span>
<span class="sd">                Note that at least one of `mask` or `sample_sizes` needs to be set. The mask is truncated to the maximum sample size in the batch.</span>
<span class="sd">            sample_sizes: Number of valid entries for all samples (corresponding to the :attr:`sample_sizes` tensor of :class:`RaggedBatch`, see description above).</span>
<span class="sd">                If not set, `mask` is internally used to create a sample sizes tensor.</span>
<span class="sd">                Note that at least one of `mask` or `sample_sizes` needs to be set.</span>
<span class="sd">            non_uniform_dim: Dimension in which the batch is non-uniform, default: 1</span>

<span class="sd">        Note:</span>
<span class="sd">            The number of batch dimensions is determined from the shape of the provided `mask` or `sample_sizes` tensor.</span>

<span class="sd">        Warning:</span>
<span class="sd">            If both `mask` and `sample_sizes` are set, they need to be consistent with each other. This is</span>
<span class="sd">            not checked in the constructor. Inconsistent masks and sample sizes will lead to undefined behavior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">non_uniform_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">non_uniform_dim</span> <span class="o">=</span> <span class="n">sample_sizes</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">non_uniform_dim</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either `sample_sizes` or `mask` needs to be set&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sample_sizes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sample_sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">non_uniform_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">max_sample_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">non_uniform_dim</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_sample_size</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">non_uniform_dim</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_sample_size</span><span class="p">)</span> <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="n">non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_init_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="o">*</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">],</span>
            <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">],</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="o">=</span> <span class="n">SetPaddedTo</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_sample_sizes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

<div class="viewcode-block" id="RaggedBatch.Empty">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.Empty">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">Empty</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">num_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">non_uniform_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
        <span class="n">num_batch_dims</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create an empty instance.</span>

<span class="sd">        The so created instance has a size of 0 along all dimensions.</span>

<span class="sd">        Note:</span>
<span class="sd">            If neither `num_batch_dims` nor `batch_shape` is provided, the number of batch dimensions is 1 and the batch shape is (0,).</span>

<span class="sd">        Args:</span>
<span class="sd">            num_dims: Total number of dimensions</span>
<span class="sd">            non_uniform_dim: The non-uniform dimension</span>
<span class="sd">            device: Device to use for the instance</span>
<span class="sd">            num_batch_dims: Number of batch dimensions. If provided, `batch_shape` cannot be set and size 0 is</span>
<span class="sd">                assumed for all batch dimensions.</span>
<span class="sd">            batch_shape: Shape of the batch (can be a sequence of ints or a single int in case of a single batch dimension).</span>
<span class="sd">                If not provided, the batch shape is (0,) * num_batch_dims. If provided, `num_batch_dims` cannot be set</span>
<span class="sd">                and the number of batch dimensions is inferred from the shape.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The resulting empty :class:`RaggedBatch` instance</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">num_batch_dims</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">batch_shape</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;Either num_batch_dims or batch_shape can be provided, but not both&quot;</span>

        <span class="k">if</span> <span class="n">num_batch_dims</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_batch_dims</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">batch_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
        <span class="k">elif</span> <span class="n">batch_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">num_batch_dims</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Number of batch dimensions needs to be greater than 0&quot;</span>
            <span class="n">batch_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">num_batch_dims</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Batch shape needs to be a non-empty sequence&quot;</span>
            <span class="n">num_batch_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">)</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_dims</span>
        <span class="p">),</span> <span class="s2">&quot;Number of batch dimensions needs to be less than the total number of dimensions&quot;</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">non_uniform_dim</span> <span class="o">&gt;=</span> <span class="n">num_batch_dims</span> <span class="ow">and</span> <span class="n">non_uniform_dim</span> <span class="o">&lt;</span> <span class="n">num_dims</span>
        <span class="p">),</span> <span class="s2">&quot;Non-uniform dimension needs to be in the range [num_batch_dims; num_dims[&quot;</span>

        <span class="n">sample_sizes_shape</span> <span class="o">=</span> <span class="n">batch_shape</span>
        <span class="n">mask_shape</span> <span class="o">=</span> <span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
        <span class="n">tensor_shape</span> <span class="o">=</span> <span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_dims</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">))</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mask_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">sample_sizes_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">sizes</span><span class="p">,</span> <span class="n">non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.FromFullTensor">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.FromFullTensor">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">FromFullTensor</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">full_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">non_uniform_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_batch_dims</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a :class:`RaggedBatch` instance from a tensor representing a uniform-sized batch.</span>

<span class="sd">        Args:</span>
<span class="sd">            full_tensor: Tensor to convert into a :class:`RaggedBatch` instance</span>
<span class="sd">            non_uniform_dim: Dimension to use as the non-uniform dimension.</span>
<span class="sd">                Note that while in this special case, all dimensions are uniform,</span>
<span class="sd">                the non-uniform dimension has a special meaning</span>
<span class="sd">                (e.g. for :func:`get_non_uniform_dimension_transposed_to`, and many other functions) and</span>
<span class="sd">                needs to be set.</span>
<span class="sd">            num_batch_dims: Number of batch dimensions in the tensor. Default: 1</span>

<span class="sd">        Returns:</span>
<span class="sd">            The resulting :class:`RaggedBatch` instance containing the input tensor</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">full_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">num_batch_dims</span><span class="p">]</span>
        <span class="n">sample_size</span> <span class="o">=</span> <span class="n">full_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">non_uniform_dim</span><span class="p">]</span>

        <span class="k">assert</span> <span class="n">num_batch_dims</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Number of batch dimensions needs to be greater than 0&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">non_uniform_dim</span> <span class="o">&gt;=</span> <span class="n">num_batch_dims</span> <span class="ow">and</span> <span class="n">non_uniform_dim</span> <span class="o">&lt;</span> <span class="n">full_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Non-uniform dimension needs to be in the range [</span><span class="si">{</span><span class="n">num_batch_dims</span><span class="si">}</span><span class="s2">; full_tensor.dim()[&quot;</span>

        <span class="n">mask_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">mask_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">full_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">sample_sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">full_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">full_tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="n">non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the data tensor</span>

<span class="sd">        See the description of :class:`RaggedBatch` for more information on `tensor`.</span>

<span class="sd">        For setting the data tensor, use :func:`set_tensor`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">mask</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the mask tensor</span>

<span class="sd">        See the description of :class:`RaggedBatch` for more information on `mask`.</span>

<span class="sd">        The mask indicates which elements are valid (`True`) and which are not (`False`).</span>
<span class="sd">        It has dimensions: ``(*batch_dims_shape, max_sample_size)``.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_mask</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_sizes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the sample sizes tensor</span>

<span class="sd">        See the description of :class:`RaggedBatch` for more information on `sample_sizes`.</span>

<span class="sd">        The sample sizes tensor contains the actual sizes of each sample in the batch</span>
<span class="sd">        along the non-uniform dimension.</span>
<span class="sd">        Its dimensions are ``batch_dims_shape``.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_sample_sizes</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">non_uniform_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the non-uniform dimension&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_batch_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the number of batch dimensions&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the batch shape&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">total_num_samples_in_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the total number of samples in the batch&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">total_num_entries</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the total number of entries.</span>

<span class="sd">        This is the accumulated number of valid entries along the non-uniform dimension over all samples in the batch.</span>
<span class="sd">        This information is computed from the :attr:`sample_sizes` tensor when it is first accessed and re-used on subsequent calls.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_num_targets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_total_num_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_num_targets</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">max_sample_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the maximum sample size in the batch&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">]</span>

<div class="viewcode-block" id="RaggedBatch.as_self_with_cloned_data">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.as_self_with_cloned_data">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">as_self_with_cloned_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a copy, where the data tensor (i.e. :attr:`tensor`) is cloned (while mask and sample sizes are shared)&quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.create_with_sample_sizes_like_self">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.create_with_sample_sizes_like_self">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_with_sample_sizes_like_self</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">non_uniform_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a :class:`RaggedBatch` instance with the same batch shape and sample sizes as `this`</span>

<span class="sd">        Note that while the sample sizes are the same, the total number of dimensions,</span>
<span class="sd">        the non-uniform dimension, and the size of the `data` tensor except in the</span>
<span class="sd">        batch and the non-uniform dimensions may be different.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor: Data to set for the new instance (padded tensor)</span>
<span class="sd">            non_uniform_dim: Non-uniform dimension (in `tensor`). Can be set to `None` to use the same</span>
<span class="sd">                dimension as `this`. Default: `None`</span>
<span class="sd">            device: Device on which to create the resulting :class:`RaggedBatch` instance. If not provided,</span>
<span class="sd">                the device of the input `tensor` is used.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Resulting :class:`RaggedBatch` instance with the same batch shape and sample sizes as `this`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Note that for checking the upper bound for the non-uniform dimension and handling negative values,</span>
        <span class="c1"># we use the tensor for the number of dimensions, as this will be the data tensor of the new RaggedBatch</span>
        <span class="c1"># to create.</span>
        <span class="c1"># For the lower bound, we use the number of batch dimensions of `self`, as the batch dimensions of the new</span>
        <span class="c1"># RaggedBatch to create will be the same as the batch dimensions of `self`.</span>
        <span class="k">if</span> <span class="n">non_uniform_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">non_uniform_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span>
        <span class="k">elif</span> <span class="n">non_uniform_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">non_uniform_dim</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="n">non_uniform_dim</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">non_uniform_dim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span> <span class="ow">and</span> <span class="n">non_uniform_dim</span> <span class="o">&lt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Non-uniform dimension needs to be in the range [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="si">}</span><span class="s2">; </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2">[&quot;</span>

        <span class="c1"># Check that all batch dimensions match</span>
        <span class="k">assert</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">,</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Batch shape of tensor does not match required batch shape:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Expected batch shape: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Got batch shape: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="k">assert</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">non_uniform_dim</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">],</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Non-uniform dimension size of tensor does not match required non-uniform dimension size:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Expected non-uniform dimension size: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Got non-uniform dimension size: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">non_uniform_dim</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">device</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">sample_sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="n">non_uniform_dim</span><span class="p">)</span>
        <span class="c1"># In case this number is already computed, it can be re-used in the new RaggedBatch</span>
        <span class="n">res</span><span class="o">.</span><span class="n">_total_num_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_num_targets</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.get_non_uniform_dimension_transposed_to">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.get_non_uniform_dimension_transposed_to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_non_uniform_dimension_transposed_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get with the non-uniform dimension transposed to a given dimension.</span>

<span class="sd">        If the given dimension is already the non-uniform dimension, `self` is returned.</span>

<span class="sd">        Info:</span>
<span class="sd">            The non-uniform dimension cannot be set to a batch dimension (i.e., any dimension &lt; num_batch_dims).</span>

<span class="sd">        Args:</span>
<span class="sd">            dim: Dimension to transpose the current non-uniform dimension to</span>

<span class="sd">        Returns:</span>
<span class="sd">            Resulting :class:`RaggedBatch` instance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">dim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span> <span class="ow">and</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Non-uniform dimensions needs to be in the range [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="si">}</span><span class="s2">; tensor.dim()[&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor_transposed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="n">tensor_transposed</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.get_existence_weights">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.get_existence_weights">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_existence_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the existence weights</span>

<span class="sd">        The existence weights are 1.0 for the contained entries (i.e. entries corresponding to actual</span>
<span class="sd">        data as opposed to padded fillers)  and 0.0 for filler entries.</span>

<span class="sd">        In contrast to `self.mask`, the dimensionality and shape of the weights</span>
<span class="sd">        correspond to the dimensionality and shape of the data. This means that the mask</span>
<span class="sd">        can be directly applied to the data tensor (i.e. :attr:`tensor`), regardless of the number of dimensions or</span>
<span class="sd">        which dimension is the non-uniform dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            dtype: Type for the existence weights. Default: torch.float32</span>

<span class="sd">        Returns:</span>
<span class="sd">            The resulting weights tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span>
        <span class="n">num_dims_extra</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="n">mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="n">shape_weights_reshape</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="n">num_dims_extra</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape_weights_reshape</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="n">weights_num_repeats</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># Don&#39;t repeat along batch dimensions</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">):</span>
            <span class="n">weights_num_repeats</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">weights_num_repeats</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">weights_num_repeats</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weights</span></div>


<div class="viewcode-block" id="RaggedBatch.with_padded_set_to">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.with_padded_set_to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">with_padded_set_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value_to_set</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set filler/padded entries in the data (i.e. :attr:`tensor`) to a fixed value.</span>

<span class="sd">        Note:</span>
<span class="sd">            This operation is not performed in-place, i.e. `this.tensor` is not changed. For an in-place</span>
<span class="sd">            operation, use :func:`set_padded_to` instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            value_to_set: Value to set for padded entries.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Like self, but with the padded values set</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">as_self_with_cloned_data</span><span class="p">()</span>
        <span class="n">res</span><span class="o">.</span><span class="n">set_padded_to</span><span class="p">(</span><span class="n">value_to_set</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.set_padded_to">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.set_padded_to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_padded_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value_to_set</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set filler/padded entries in the data tensor (i.e. :attr:`tensor`) to a fixed value in-place.</span>

<span class="sd">        Note:</span>
<span class="sd">            Note that as this operation is in-place. This means that `this.tensor` is changed.</span>
<span class="sd">            No new :class:`RaggedBatch` instance is created. If this is not desired, use</span>
<span class="sd">            :func:`with_padded_set_to` instead, which is not in-place and returns a new :class:`RaggedBatch` instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            value_to_set: Value to set for padded entries.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">SetPaddedTo</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="n">value_to_set</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span> <span class="o">=</span> <span class="n">tensor</span></div>


<div class="viewcode-block" id="RaggedBatch.repeat_samples">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.repeat_samples">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">repeat_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_repeats</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
        <span class="n">batch_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Repeat along a single batch dimension</span>

<span class="sd">        Args:</span>
<span class="sd">            num_repeats: Number of times to repeat. In case of a single value, the dimension in which to repeat</span>
<span class="sd">                is specified by `batch_dim`. In case of a sequence, the sequence needs to have the same length as</span>
<span class="sd">                the number of batch dimensions and `batch dim` must not be set.</span>
<span class="sd">            batch_dim: Which batch dimension to repeat along. Can only be set if `num_repeats` is a single value.</span>
<span class="sd">                If not set (and `num_repeats` is a single value), `0` is used.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Resulting :class:`RaggedBatch` instance with the samples repeated</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_repeats</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">use_num_repeats</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">batch_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_dim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;batch_dim must be in range [0, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_repeats</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">num_repeats</span><span class="p">)</span>
            <span class="n">use_num_repeats</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">num_repeats</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;num_repeats must be a sequence of length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">assert</span> <span class="n">batch_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;batch_dim must be None if num_repeats is a sequence&quot;</span>

        <span class="k">if</span> <span class="n">use_num_repeats</span><span class="p">:</span>
            <span class="c1"># Create repeat specifications for the tensor</span>
            <span class="n">tensor_num_reps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
            <span class="n">tensor_num_reps</span><span class="p">[</span><span class="n">batch_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_repeats</span>
            <span class="n">mask_repeats</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Initialize all dims to 1</span>
            <span class="n">mask_repeats</span><span class="p">[</span><span class="n">batch_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_repeats</span>  <span class="c1"># Repeat only the specified batch dimension</span>
            <span class="n">sample_sizes_repeats</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>
            <span class="n">sample_sizes_repeats</span><span class="p">[</span><span class="n">batch_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_repeats</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor_num_reps</span> <span class="o">=</span> <span class="n">num_repeats</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">)</span>
            <span class="n">mask_repeats</span> <span class="o">=</span> <span class="n">num_repeats</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">sample_sizes_repeats</span> <span class="o">=</span> <span class="n">num_repeats</span>

        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">tensor_num_reps</span><span class="p">)</span>

        <span class="c1"># Mask and sample sizes only need to be updated if they are computed already</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">mask_repeats</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">sample_sizes</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">sample_sizes_repeats</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.unsqueeze_batch_dim">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.unsqueeze_batch_dim">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">unsqueeze_batch_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Unsqueeze a batch dimension</span>

<span class="sd">        Important:</span>
<span class="sd">            The dimension to unsqueeze has to be among the batch dimensions (including adding a new batch dimension</span>
<span class="sd">            after the currently last batch dimensions, i.e. `dim=self.num_batch_dims`).</span>

<span class="sd">            For unsqueezing a data dimension, use :meth:`unsqueeze_data_dim` instead.</span>

<span class="sd">        Note:</span>
<span class="sd">            As the batch dimensions are always before the non-uniform dimension, the non-uniform dimension is shifted by 1 accordingly.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; example_batch.num_batch_dims</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; example_batch.non_uniform_dim</span>
<span class="sd">            4</span>
<span class="sd">            &gt;&gt;&gt; example_batch_unsqueezed = example_batch.unsqueeze_batch_dim(1)</span>
<span class="sd">            &gt;&gt;&gt; example_batch_unsqueezed.non_uniform_dim</span>
<span class="sd">            5</span>

<span class="sd">        Args:</span>
<span class="sd">            dim: Batch dimension to add. Has to be in range [0, :attr:`num_batch_dims`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            Resulting :class:`RaggedBatch` instance with the batch dimension added</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;dim must be in range [0, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="si">}</span><span class="s2">]&quot;</span>

        <span class="n">tensor_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">mask_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">sample_sizes_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">res_non_uniform_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor_res</span><span class="p">,</span> <span class="n">mask_res</span><span class="p">,</span> <span class="n">sample_sizes_res</span><span class="p">,</span> <span class="n">res_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.squeeze_batch_dim">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.squeeze_batch_dim">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">squeeze_batch_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Squeeze a batch dimension</span>

<span class="sd">        Note:</span>
<span class="sd">            This operation is not performed in-place, i.e. `this.tensor` is not changed.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_dim: Batch dimension to squeeze. Has to be in range [0, :attr:`num_batch_dims`).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Resulting :class:`RaggedBatch` instance with the batch dimension squeezed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">batch_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_dim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;batch_dim must be in range [0, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">[</span><span class="n">batch_dim</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Batch dimension </span><span class="si">{</span><span class="n">batch_dim</span><span class="si">}</span><span class="s2"> has size </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">[</span><span class="n">batch_dim</span><span class="p">]</span><span class="si">}</span><span class="s2"> &gt; 1. Cannot squeeze.&quot;</span>
            <span class="p">)</span>

        <span class="n">tensor_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">)</span>
        <span class="n">mask_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">sample_sizes_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">res_non_uniform_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor_res</span><span class="p">,</span> <span class="n">mask_res</span><span class="p">,</span> <span class="n">sample_sizes_res</span><span class="p">,</span> <span class="n">res_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.reshape_batch_dims">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.reshape_batch_dims">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">reshape_batch_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reshape the batch dimensions</span>

<span class="sd">        Note:</span>
<span class="sd">            This operation is not performed in-place, i.e. `this.tensor` is not changed.</span>

<span class="sd">        Important:</span>
<span class="sd">            The non-uniform dimension is adjusted to the new batch shape.</span>

<span class="sd">        Args:</span>
<span class="sd">            new_batch_shape: New batch shape</span>

<span class="sd">        Returns:</span>
<span class="sd">            Resulting :class:`RaggedBatch` instance with the batch dimensions reshaped</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">new_batch_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,)</span>

        <span class="n">tensor_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span> <span class="p">:])</span>
        <span class="n">mask_res</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span> <span class="p">:])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">sample_sizes_res</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">new_batch_shape</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">res_non_uniform_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor_res</span><span class="p">,</span> <span class="n">mask_res</span><span class="p">,</span> <span class="n">sample_sizes_res</span><span class="p">,</span> <span class="n">res_non_uniform_dim</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.flatten_batch_dims">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.flatten_batch_dims">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">flatten_batch_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Flatten the batch dimensions</span>

<span class="sd">        Note:</span>
<span class="sd">            This operation is not performed in-place, i.e. `this.tensor` is not changed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_batch_dims</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.broadcast_batch_dims_to_shape">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.broadcast_batch_dims_to_shape">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_batch_dims_to_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">,])</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
        <span class="n">new_batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;New batch shape </span><span class="si">{</span><span class="n">new_batch_shape</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> dimensions, but </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="si">}</span><span class="s2"> dimensions are expected.&quot;</span>

        <span class="n">batch_shape_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span><span class="p">)</span>
        <span class="n">multiplier</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">new_batch_shape</span> <span class="o">/</span> <span class="n">batch_shape_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span>
            <span class="n">multiplier</span> <span class="o">*</span> <span class="n">batch_shape_tensor</span> <span class="o">==</span> <span class="n">new_batch_shape</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Cannot broadcast batch dimensions of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">new_batch_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeat_samples</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">multiplier</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.broadcast_batch_dims">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.broadcast_batch_dims">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_batch_dims</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">RaggedBatch</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">RaggedBatch</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the batch dimensions of a sequence of :class:`RaggedBatch` instances to common batch dimensions.</span>

<span class="sd">        Args:</span>
<span class="sd">            data: Sequence of :class:`RaggedBatch` instances</span>

<span class="sd">        Returns:</span>
<span class="sd">            Sequence of :class:`RaggedBatch` instances with the batch dimensions broadcasted to the common batch dimensions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">batch_shapes_stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_shapes</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Cannot broadcast as number of batch dimensions does not match.&quot;</span>
        <span class="n">max_batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">batch_shapes_stacked</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="n">multipliers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">max_batch_shape</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_shapes_stacked</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span>
                <span class="n">batch_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">multipliers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_batch_shape</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Cannot broadcast batch dimensions of </span><span class="si">{</span><span class="n">dt</span><span class="o">.</span><span class="n">batch_shape</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">max_batch_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">repeat_samples</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">multipliers</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.to_device">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.to_device">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get on device&quot;&quot;&quot;</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Mask and sample sizes only need to be updated if they are computed already.</span>
        <span class="c1"># Note that while ensuring they are available here would potentially avoid re-computation,</span>
        <span class="c1"># it would also mean more memory transfers.</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">sample_sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.cpu">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.cpu">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get on the CPU&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_CPU</span><span class="p">)</span></div>


<div class="viewcode-block" id="RaggedBatch.to_dtype">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.to_dtype">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get with :attr:`tensor` converted to given data type&quot;&quot;&quot;</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># Mask and sample sizes updated (to avoid double computation if needed for both `this` and the new instance)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.detach">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.detach">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">detach</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get with detached :attr:`tensor`&quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.apply">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.apply">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">proc_step</span><span class="p">:</span> <span class="n">ProcStep</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">RaggedBatch</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">RaggedBatch</span><span class="p">,</span> <span class="o">...</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply a function to :attr:`tensor` and get results as new `RaggedBatch` instance(s).</span>

<span class="sd">        See the `proc_step` parameter for requirements for the used function.</span>

<span class="sd">        Important:</span>
<span class="sd">            It is important to make sure that the tensors returned by `proc_step` fulfill the output requirements</span>
<span class="sd">            regarding the non-uniform dimension, sample sizes, and regarding the valid entries being stored first (i.e. lower indices),</span>
<span class="sd">            followed by filler values along the non-uniform dimension to ensure that the resulting :class:`RaggedBatch` instances are correct.</span>
<span class="sd">            See the `proc_step` parameter for more details.</span>

<span class="sd">        Args:</span>
<span class="sd">            proc_step: Function to process the data tensor. All the defined inputs (see below) are</span>
<span class="sd">                expected to be positional arguments.</span>

<span class="sd">                Args:</span>
<span class="sd">                    tensor: Will contain :attr:`tensor` of `this`</span>
<span class="sd">                    mask: If part of the function signature, will contain :attr:`mask` of `this`</span>
<span class="sd">                    sample_sizes: As a positional argument, this can only be part of the function</span>
<span class="sd">                        signature if `mask` is. If used, will contain :attr:`sample_sizes` of `this`</span>
<span class="sd">                Returns:</span>
<span class="sd">                    Either a tensor or a tuple of tensors. For each tensor, a</span>
<span class="sd">                    :class:`RaggedBatch` instance will be output from `apply()`. Note that for each</span>
<span class="sd">                    returned tensor, the non-uniform dimension, as well as the number of entries along</span>
<span class="sd">                    that dimension, must correspond to `this`. Also, for each sample, the the valid</span>
<span class="sd">                    entries must be located before any filler entries along the non-uniform dimension (as is in general the case for</span>
<span class="sd">                    the data stored in a :class:`RaggedBatch`, see documentation of the class). Note that the last</span>
<span class="sd">                    point is generally fulfilled if no permutations are applied to the data tensor, as the input `tensor`</span>
<span class="sd">                    contains valid entries first, followed by filler entries.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :class:`RaggedBatch` instance or tuple of :class:`RaggedBatch` instances (depending on the output of `proc_step`),</span>
<span class="sd">            with the function applied to the data (i.e. to :attr:`tensor`).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_args</span> <span class="o">=</span> <span class="n">proc_step</span><span class="o">.</span><span class="vm">__code__</span><span class="o">.</span><span class="n">co_argcount</span>
        <span class="k">if</span> <span class="n">num_args</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="p">,)</span>
        <span class="k">elif</span> <span class="n">num_args</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">num_args</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Function </span><span class="si">{</span><span class="n">proc_step</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="n">num_args</span><span class="si">}</span><span class="s2"> arguments, but only 1, 2, or 3 are supported.&quot;</span>
            <span class="p">)</span>
        <span class="n">res_tensor</span> <span class="o">=</span> <span class="n">proc_step</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res_tensor</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="p">[</span><span class="n">RaggedBatch</span><span class="p">(</span><span class="n">rd</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">rd</span> <span class="ow">in</span> <span class="n">res_tensor</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">RaggedBatch</span><span class="p">(</span><span class="n">res_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.set_tensor">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.set_tensor">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set :attr:`tensor`.</span>

<span class="sd">        Important:</span>
<span class="sd">            The batch shape, the non-uniform dimension, and the number of entries along</span>
<span class="sd">            that dimension must correspond to `this`. Also, for each sample, the valid</span>
<span class="sd">            entries must be located before any filler entries (as is in general the case for</span>
<span class="sd">            the data stored in a :class:`RaggedBatch` instance, see documentation of the class).</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor: Data tensor to set</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check that all batch dimensions match</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">]</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Batch shape of data to set </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2"> does not match current batch shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>

        <span class="c1"># Check that the non-uniform dimension size matches</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">]</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Maximum sample size of data to set (</span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">]</span><span class="si">}</span><span class="s2">) does not match current maximum sample size (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">]</span><span class="si">}</span><span class="s2">).&quot;</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">tensor</span><span class="o">.</span><span class="n">device</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Device of the data to set (</span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">) does not match current device (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">).&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span> <span class="o">=</span> <span class="n">tensor</span></div>


<div class="viewcode-block" id="RaggedBatch.split">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.split">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Split contained data (i.e. the data in :attr:`tensor`) into individual samples.</span>

<span class="sd">        The batch dimensions are preserved in the nested list structure.</span>
<span class="sd">        For example, if the batch shape is (2, 3), the result will be a list of 2 lists,</span>
<span class="sd">        each containing 3 tensors.</span>

<span class="sd">        The returned samples are cropped to not contain any filler entries. This means that the</span>
<span class="sd">        returned tensors correspond to the actual sample sizes.</span>

<span class="sd">        Example:</span>

<span class="sd">            In the example below, the :meth:`split` operation is applied to a :class:`RaggedBatch` instance with</span>
<span class="sd">            a batch size of 4 (single batch dimension) and a maximum sample size of 3, resulting in a list</span>
<span class="sd">            of 4 tensors, and each tensor corresponding to a single sample without padded filler entries.</span>
<span class="sd">            Note that in the image below:</span>

<span class="sd">              - Letters indicate data entries that are valid (i.e. correspond to the actual data).</span>
<span class="sd">              - &#39;*&#39; Indicates padded filler entries (i.e. invalid entries) in the data.</span>

<span class="sd">            .. image:: images/Split_ragged.png</span>
<span class="sd">                :alt: Illustration of the split operation</span>
<span class="sd">                :align: center</span>

<span class="sd">            Each depicted element may represent a single value (corresponding to scalar data and 0 data dimensions),</span>
<span class="sd">            or itself represent a non-scalar entry (in case for one or more data dimensions).</span>

<span class="sd">        Returns:</span>
<span class="sd">            The individual samples in a nested list structure that reflects the original batch shape.</span>
<span class="sd">            The individual tensors correspond to the actual sample sizes, and do not contain padded filler entries.</span>

<span class="sd">            For a single batch dimension, returns a flat list of tensors.</span>
<span class="sd">            For multiple batch dimensions, returns a nested list structure mirroring the batch dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure non_uniform_dim is at the position right after the batch dimensions for easier processing</span>
        <span class="n">need_transpose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>

        <span class="k">if</span> <span class="n">need_transpose</span><span class="p">:</span>
            <span class="n">original_non_uniform_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span>
            <span class="n">self_preshaped</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_non_uniform_dimension_transposed_to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self_preshaped</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="n">tensor_to_use</span> <span class="o">=</span> <span class="n">self_preshaped</span><span class="o">.</span><span class="n">tensor</span>
        <span class="n">sample_sizes_to_use</span> <span class="o">=</span> <span class="n">self_preshaped</span><span class="o">.</span><span class="n">sample_sizes</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_recursive_split</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="n">batch_idx</span><span class="o">=</span><span class="p">(),</span> <span class="n">batch_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">batch_dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">:</span>
                <span class="c1"># At the innermost level, extract the actual sample by slicing to the correct size</span>
                <span class="n">sample_size</span> <span class="o">=</span> <span class="n">sample_sizes</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">][:</span><span class="n">sample_size</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">need_transpose</span><span class="p">:</span>
                    <span class="n">original_non_uniform_dim_unbatched</span> <span class="o">=</span> <span class="n">original_non_uniform_dim</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span>
                    <span class="n">sample</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">original_non_uniform_dim_unbatched</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">sample</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># At intermediate levels, create a list for this batch dimension</span>
                <span class="k">return</span> <span class="p">[</span>
                    <span class="n">_recursive_split</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="p">,),</span> <span class="n">batch_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">batch_dim</span><span class="p">])</span>
                <span class="p">]</span>

        <span class="c1"># Use recursive function to create nested list structure</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_recursive_split</span><span class="p">(</span><span class="n">tensor_to_use</span><span class="p">,</span> <span class="n">sample_sizes_to_use</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="RaggedBatch.unsqueeze_data_dim">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.unsqueeze_data_dim">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">unsqueeze_data_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Unsqueeze the data tensor (i.e. :attr:`tensor`) along a dimension.</span>

<span class="sd">        Important:</span>
<span class="sd">            The dimension to unsqueeze has to be after the batch dimensions (including adding a new data dimension</span>
<span class="sd">            right after the batch dimensions, i.e. `dim=self.num_batch_dims`).</span>

<span class="sd">            For unsqueezing a batch dimension, use :meth:`unsqueeze_batch_dim` instead.</span>

<span class="sd">        Note:</span>
<span class="sd">            If the new dimension is inserted before the current non-uniform dimension, the</span>
<span class="sd">            non-uniform dimension is shifted by 1 accordingly.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; example_batch.num_batch_dims</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; example_batch.non_uniform_dim</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; example_batch_unsqueezed = example_batch.unsqueeze_data_dim(1)</span>
<span class="sd">            &gt;&gt;&gt; example_batch_unsqueezed.non_uniform_dim</span>
<span class="sd">            2</span>

<span class="sd">        Args:</span>
<span class="sd">            dim: Dimension index into which to insert the new dimension</span>

<span class="sd">        Returns:</span>
<span class="sd">            Like self, but with the new dimension added, and the non-uniform</span>
<span class="sd">            dimension shifted accordingly if needed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">dim</span>
            <span class="c1"># Note that dim can be equal to self._tensor.dim(), in which case it is added after the last dimension</span>
            <span class="k">assert</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">(),</span> <span class="s2">&quot;Dimension outside the available range&quot;</span>
        <span class="k">assert</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batch_dims</span><span class="p">,</span> <span class="s2">&quot;Can only add dimensions after the batch dimensions&quot;</span>

        <span class="n">tensor_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="c1"># Check if the new dimension is inserted before the non-uniform dimension and if this is the case,</span>
        <span class="c1"># account for the fact that the non-uniform dimension was moved back by 1 dimension.</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="p">:</span>
            <span class="n">non_uniform_dim_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">non_uniform_dim_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span>

        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="n">tensor_res</span><span class="p">,</span> <span class="n">non_uniform_dim_res</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="RaggedBatch.__getitem__">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.__getitem__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Item read access for :attr:`tensor`</span>

<span class="sd">        This is a shorthand for: `... = self.tensor[item]`.</span>

<span class="sd">        Note than as such, this allows for access to filler entries and does not check whether the accessed</span>
<span class="sd">        elements correspond to valid or filler entries.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="p">[</span><span class="n">item</span><span class="p">]</span></div>


<div class="viewcode-block" id="RaggedBatch.__setitem__">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.__setitem__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Item write access for :attr:`tensor`</span>

<span class="sd">        This is a shorthand for: `self.tensor[item] = ...`.</span>

<span class="sd">        Note than as such, this allows for access to filler entries and does not check whether the accessed</span>
<span class="sd">        elements correspond to valid or filler entries.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the used device&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">device</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the shape of the data tensor (i.e. :attr:`tensor`)</span>

<span class="sd">        The non-uniform dimension is reported as the size of the underlying :attr:`tensor`,</span>
<span class="sd">        i.e. to the maximum size among all samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Type of the data elements (i.e. elements of :attr:`tensor`)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dtype</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get/set whether :attr:`tensor` requires gradients&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">requires_grad</span>

    <span class="nd">@requires_grad</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">value</span>

<div class="viewcode-block" id="RaggedBatch.retain_grad">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.retain_grad">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">retain_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Retain gradients for :attr:`tensor`&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">()</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">retains_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get whether gradients are retained for :attr:`tensor`&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">retains_grad</span>

<div class="viewcode-block" id="RaggedBatch.size">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.size">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shorthand for `self.tensor.size(*args, **kwargs)`&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="RaggedBatch.dim">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.dim">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the number of dimensions (of :attr:`tensor`)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span></div>


<div class="viewcode-block" id="RaggedBatch.int">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.int">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">int</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">int</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.long">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.long">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">long</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">long</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.bool">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.bool">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">bool</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.half">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.half">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">half</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">half</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.bfloat16">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.bfloat16">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">bfloat16</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.float">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.float">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">float</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">float</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.double">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.double">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">double</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">double</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.cfloat">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.cfloat">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">cfloat</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">cfloat</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.cdouble">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.cdouble">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">cdouble</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert type of :attr:`tensor` elements&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">cdouble</span><span class="p">())</span></div>


<div class="viewcode-block" id="RaggedBatch.to">
<a class="viewcode-back" href="../../../../contained_package_docs_mirror/batching_helpers/docs/api.html#accvlab.batching_helpers.RaggedBatch.to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RaggedBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new :class:`RaggedBatch` instance converted as specified.</span>

<span class="sd">        This is a shorthand for:</span>
<span class="sd">        `self.create_with_sample_sizes_like_self(self._tensor.to(*args, **kwargs))`.</span>

<span class="sd">        Note:</span>
<span class="sd">            The conversion is primarily performed on the :attr:`tensor`.</span>
<span class="sd">            The :attr:`sample_sizes` and :attr:`mask` are adjusted accordingly if needed</span>
<span class="sd">            (e.g. when converting to a different device, but not when converting to a different</span>
<span class="sd">            dtype, as the dtype is only relevant for the :attr:`tensor`).</span>

<span class="sd">        Args:</span>
<span class="sd">            *args: Arguments for :meth:`torch.Tensor.to` as applied to :attr:`tensor`</span>
<span class="sd">            **kwargs: Keyword arguments for :meth:`torch.Tensor.to` as applied to :attr:`tensor`</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new :class:`RaggedBatch` instance with the :attr:`tensor` converted to the given type</span>
<span class="sd">            and the :attr:`sample_sizes` and :attr:`mask` adjusted accordingly if needed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_with_sample_sizes_like_self</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>


    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">mask_str</span> <span class="o">=</span> <span class="s2">&quot;*uninitialized*&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;mask=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">sample_sizes_str</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;*uninitialized*&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;sample_sizes=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_sizes</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;RaggedBatch(tensor=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="si">}</span><span class="s2">, mask=</span><span class="si">{</span><span class="n">mask_str</span><span class="si">}</span><span class="s2">, samples_sizes=</span><span class="si">{</span><span class="n">sample_sizes_str</span><span class="si">}</span><span class="s2">, non_uniform_dim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_uniform_dim</span><span class="si">}</span><span class="s2">, batch_shape=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="k">return</span> <span class="n">res</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>