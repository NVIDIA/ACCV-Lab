

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2D Object Detection Pipeline Setup &mdash; ACCV-Lab 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/custom.css?v=9282052d" />

  
      <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="StreamPETR Pipeline" href="../stream_petr/index.html" />
    <link rel="prev" title="2D Object Detection Pipeline" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            ACCV-Lab
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">General Info</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../project_overview/README.html">ACCV-Lab Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../guides_index.html">Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contained Packages</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../on_demand_video_decoder/docs/index.html">On Demand Video Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../batching_helpers/docs/index.html">Batching Helpers</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">DALI Pipeline Framework</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../design.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/main_api.html">Main API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/additional_api.html">Additional API Reference</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../examples.html">Examples</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../examples.html#pipeline-setup-examples">Pipeline Setup Examples</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="index.html">2D Object Detection Pipeline</a><ul class="current">
<li class="toctree-l5 current"><a class="current reference internal" href="#">2D Object Detection Pipeline Setup</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../stream_petr/index.html">StreamPETR Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../flexible_step/index.html">Flexible Step Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../examples.html#data-loaders-for-nuscenes">Data Loaders for NuScenes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../evaluation.html">Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../draw_heatmap/docs/index.html">Draw Heatmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim_test_tools/docs/index.html">Optimization Testing Tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">ACCV-Lab</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">DALI Pipeline Framework</a></li>
          <li class="breadcrumb-item"><a href="../../examples.html">Examples</a></li>
          <li class="breadcrumb-item"><a href="index.html">2D Object Detection Pipeline</a></li>
      <li class="breadcrumb-item active">2D Object Detection Pipeline Setup</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/contained_package_docs_mirror/dali_pipeline_framework/docs/examples/2d_object_detection/pipeline_setup.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="d-object-detection-pipeline-setup">
<h1>2D Object Detection Pipeline Setup<a class="headerlink" href="#d-object-detection-pipeline-setup" title="Link to this heading"></a></h1>
<p>This page documents the DALI-based 2D object detection input pipeline as implemented in
<code class="docutils literal notranslate"><span class="pre">packages/dali_pipeline_framework/examples/pipeline_setup/object_detection_2d_pipeline.py</span></code>.</p>
<section id="overview-and-goals">
<h2>Overview and Goals<a class="headerlink" href="#overview-and-goals" title="Link to this heading"></a></h2>
<div class="docutils container">
<p>This 2D object detection pipeline reads NuScenes samples, applies image decoding and augmentations,
and processed the ground truth bounding boxes (generating gaussian heatmaps and providing related
information).</p>
<p>The pipeline is configured here (see function <code class="docutils literal notranslate"><span class="pre">setup_dali_pipeline_2d_object_detection()</span></code> below).
It is meant as an example for the use of the DALI pipeline framework.</p>
</div>
</section>
<section id="details">
<h2>Details<a class="headerlink" href="#details" title="Link to this heading"></a></h2>
<p>Here, we discuss the details of the 2D object detection pipeline setup.</p>
<section id="input-data-handling">
<h3>Input Data Handling<a class="headerlink" href="#input-data-handling" title="Link to this heading"></a></h3>
<p>The first step is to ensure that input data is provided to the pipeline.
Please also see <a class="reference internal" href="../use_case_specific/nuscenes_data_loader.html"><span class="doc">Data Loading for NuScenes</span></a> for more details on the data loading
in this case and <a class="reference internal" href="../../design/input.html"><span class="doc">Input – Passing Data to the Pipeline</span></a> for a general overview of the input handling.</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/object_detection_2d_pipeline.py</span><a class="headerlink" href="#id1" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">49</span>    <span class="c1"># ===== Input data handling =====</span>
<span class="linenos">50</span>
<span class="hll"><span class="linenos">51</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">52</span>    <span class="c1"># Goal: Create an input callable (functor) which is responsible for providing the input one sample at a</span>
</span><span class="hll"><span class="linenos">53</span>    <span class="c1"># time.</span>
</span><span class="linenos">54</span>
<span class="hll"><span class="linenos">55</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">56</span>    <span class="c1"># Here, we use a NuScenesReader to read the metadata and store it in memory in a format facilitating fast</span>
</span><span class="hll"><span class="linenos">57</span>    <span class="c1"># &amp; easy sample ratrieval.</span>
</span><span class="hll"><span class="linenos">58</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">59</span>    <span class="c1"># Try to load previously converted data. If this is not possible, read in the original format &amp; convert</span>
</span><span class="linenos">60</span>    <span class="n">nuscenes_preproc_file_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">_preproc_</span><span class="si">{}</span><span class="s1">.pkl&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nuscenes_version</span><span class="p">,</span> <span class="s2">&quot;det2d&quot;</span><span class="p">)</span>
<span class="linenos">61</span>    <span class="n">input_data</span> <span class="o">=</span> <span class="n">NuScenesReader</span><span class="o">.</span><span class="n">load_data_if_available_else_create_and_store</span><span class="p">(</span>
<span class="linenos">62</span>        <span class="n">nuscenes_root_dir</span><span class="p">,</span>
<span class="linenos">63</span>        <span class="n">nuscenes_preproc_file_name</span><span class="p">,</span>
<span class="linenos">64</span>        <span class="n">nuscenes_version</span><span class="p">,</span>
<span class="linenos">65</span>        <span class="c1"># Note that to use `add_image_annotations=True`, the image annotations need to be present.</span>
<span class="linenos">66</span>        <span class="c1"># They can be generated using the `prepare_dataset.py` script in the DALI pipeline framework examples.</span>
<span class="linenos">67</span>        <span class="n">add_image_annotations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">68</span>    <span class="p">)</span>
<span class="linenos">69</span>
<span class="hll"><span class="linenos">70</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">71</span>    <span class="c1"># Create a data provider for this use case.</span>
</span><span class="hll"><span class="linenos">72</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">73</span>    <span class="c1"># Note that this data provider can output either a single image or all camera images as one single sample.</span>
</span><span class="hll"><span class="linenos">74</span>    <span class="c1"># (set as `config.image_config.use_single_images`). The use of single images is the main use-case,</span>
</span><span class="hll"><span class="linenos">75</span>    <span class="c1"># and the use of multiple images is for demonstration purposes.</span>
</span><span class="linenos">76</span>    <span class="n">input_provider</span> <span class="o">=</span> <span class="n">Nuscenes2DDetectionDataProvider</span><span class="p">(</span>
<span class="linenos">77</span>        <span class="n">nuscenes_root_dir</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">image_config</span><span class="o">.</span><span class="n">use_single_images</span>
<span class="linenos">78</span>    <span class="p">)</span>
<span class="linenos">79</span>
<span class="hll"><span class="linenos">80</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">81</span>    <span class="c1"># The actual callable uses the `input_provider` to provide the input data  Here, we use the general</span>
</span><span class="hll"><span class="linenos">82</span>    <span class="c1"># `ShuffledShardedInputCallable` provided by the package, and pass the data provider to it to</span>
</span><span class="hll"><span class="linenos">83</span>    <span class="c1"># configure it according to our use-case.</span>
</span><span class="hll"><span class="linenos">84</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">85</span>    <span class="c1"># As a side note, note that if sharding is used, the `seed` needs to be the same for all shards to ensure</span>
</span><span class="hll"><span class="linenos">86</span>    <span class="c1"># consistent splits of the dataset into the shards among the input callable objects of all shards.</span>
</span><span class="linenos">87</span>    <span class="n">input_callable</span> <span class="o">=</span> <span class="n">ShuffledShardedInputCallable</span><span class="p">(</span>
<span class="linenos">88</span>        <span class="n">input_provider</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">21</span>
<span class="linenos">89</span>    <span class="p">)</span>
<span class="linenos">90</span>
</pre></div>
</div>
</div>
</section>
<section id="define-processing-steps">
<h3>Define Processing Steps<a class="headerlink" href="#define-processing-steps" title="Link to this heading"></a></h3>
<p>Next, we define the processing steps that will be applied to the input data.
Please also see <a class="reference internal" href="../../design/pipeline_processing_steps.html"><span class="doc">Pipeline &amp; Processing Steps</span></a> for a general overview of the processing steps
and <a class="reference internal" href="../../design/sample_data_group.html"><span class="doc">Data Format: Sample Data Group</span></a> for more details on the data format.</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/object_detection_2d_pipeline.py</span><a class="headerlink" href="#id2" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 91</span>    <span class="c1"># ===== Define processing steps =====</span>
<span class="hll"><span class="linenos"> 92</span>    <span class="c1"># @NOTE: The procesing steps are defined here and composed into a pipeline afterwards.</span>
</span><span class="linenos"> 93</span>
<span class="hll"><span class="linenos"> 94</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos"> 95</span>    <span class="c1"># Note that all the used steps work both for single-image input and for samples containing all camera</span>
</span><span class="hll"><span class="linenos"> 96</span>    <span class="c1"># images.</span>
</span><span class="hll"><span class="linenos"> 97</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos"> 98</span>    <span class="c1"># Please see the introduction in the `dali-pipeline` documentation for details on the</span>
</span><span class="hll"><span class="linenos"> 99</span>    <span class="c1"># input data structure and how the individual steps are designed to achieve this flexibility.</span>
</span><span class="hll"><span class="linenos">100</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">101</span>    <span class="c1"># Also, note that there are wrapper classes available which allow to modify the steps to define which</span>
</span><span class="hll"><span class="linenos">102</span>    <span class="c1"># data is processed independently (e.g. different augmentations for different images) or consistently</span>
</span><span class="hll"><span class="linenos">103</span>    <span class="c1"># (e.g. same augmentation for multiple images). These wrapper classes are not used in this example</span>
</span><span class="hll"><span class="linenos">104</span>    <span class="c1"># pipeline, but are needed in other use-cases (see the documentation of the package, especially the</span>
</span><span class="hll"><span class="linenos">105</span>    <span class="c1"># introduction to the `dali-pipeline` package, and the API documentation for the `PipelineStepBase`</span>
</span><span class="hll"><span class="linenos">106</span>    <span class="c1"># class).</span>
</span><span class="linenos">107</span>
<span class="hll"><span class="linenos">108</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">109</span>    <span class="c1"># Image decoding step: Decode jpeg-images (CPU or GPU, depending on the configuration).</span>
</span><span class="linenos">110</span>    <span class="n">decoder</span> <span class="o">=</span> <span class="n">ImageDecoder</span><span class="p">(</span>
<span class="linenos">111</span>        <span class="s2">&quot;image&quot;</span><span class="p">,</span>
<span class="linenos">112</span>        <span class="n">use_device_mixed</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">use_device_mixed</span><span class="p">,</span>
<span class="linenos">113</span>        <span class="n">hw_decoder_load</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">hw_decoder_load</span><span class="p">,</span>
<span class="linenos">114</span>        <span class="n">as_bgr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">115</span>    <span class="p">)</span>
<span class="linenos">116</span>
<span class="hll"><span class="linenos">117</span>    <span class="c1"># @NOTE: Affine augmentation step</span>
</span><span class="linenos">118</span>
<span class="hll"><span class="linenos">119</span>    <span class="c1"># @NOTE: First, we need to define the transformations to perform.</span>
</span><span class="linenos">120</span>    <span class="n">transformation_steps</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos">121</span>        <span class="c1"># Perform a horizontal image flip (i.e. scale along the x-axis with a fixed factor of -1.0, and a</span>
<span class="linenos">122</span>        <span class="c1"># factor of 1.0 (i.e. unchanged) for the y-axis) with a probability of 0.5</span>
<span class="linenos">123</span>        <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">NonUniformScaling</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">flip_probability</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span>
<span class="linenos">124</span>        <span class="c1"># Select one of two options with respective probabilities and perform all steps in the chosen option</span>
<span class="linenos">125</span>        <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">Selection</span><span class="p">(</span>
<span class="linenos">126</span>            <span class="mf">1.0</span><span class="p">,</span>
<span class="linenos">127</span>            <span class="c1"># Probabilities for the different options. Note that exactly one option will be selected according</span>
<span class="linenos">128</span>            <span class="c1"># to the probabilities, and that therefore, the probabilities have to sum up to 1</span>
<span class="linenos">129</span>            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">scaling_probabilities</span><span class="p">,</span>
<span class="linenos">130</span>            <span class="c1"># Options</span>
<span class="linenos">131</span>            <span class="p">[</span>
<span class="linenos">132</span>                <span class="c1"># Option 1: Scaling in the range [0.6; 1.4] followed by a translation in the range</span>
<span class="linenos">133</span>                <span class="c1"># [(-100, -100); (100, 100)] followed by a.</span>
<span class="linenos">134</span>                <span class="p">[</span>
<span class="linenos">135</span>                    <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">UniformScaling</span><span class="p">(</span>
<span class="linenos">136</span>                        <span class="mf">1.0</span><span class="p">,</span>
<span class="linenos">137</span>                        <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">scaling_ranges</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
<span class="linenos">138</span>                        <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">scaling_ranges</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
<span class="linenos">139</span>                    <span class="p">),</span>
<span class="linenos">140</span>                    <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">Translation</span><span class="p">(</span>
<span class="linenos">141</span>                        <span class="mf">1.0</span><span class="p">,</span>
<span class="linenos">142</span>                        <span class="p">[</span>
<span class="linenos">143</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
<span class="linenos">144</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
<span class="linenos">145</span>                        <span class="p">],</span>
<span class="linenos">146</span>                        <span class="p">[</span>
<span class="linenos">147</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
<span class="linenos">148</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">3</span><span class="p">],</span>
<span class="linenos">149</span>                        <span class="p">],</span>
<span class="linenos">150</span>                    <span class="p">),</span>
<span class="linenos">151</span>                <span class="p">],</span>
<span class="linenos">152</span>                <span class="c1"># Option 2: Larger scaling with a fixed factor of 2.0. As we scale more, also allow for</span>
<span class="linenos">153</span>                <span class="c1"># larger translations in the range [(-300, -300); (300, 300)]</span>
<span class="linenos">154</span>                <span class="p">[</span>
<span class="linenos">155</span>                    <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">UniformScaling</span><span class="p">(</span>
<span class="linenos">156</span>                        <span class="mf">1.0</span><span class="p">,</span>
<span class="linenos">157</span>                        <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">scaling_ranges</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
<span class="linenos">158</span>                        <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">scaling_ranges</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
<span class="linenos">159</span>                    <span class="p">),</span>
<span class="linenos">160</span>                    <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">Translation</span><span class="p">(</span>
<span class="linenos">161</span>                        <span class="mf">1.0</span><span class="p">,</span>
<span class="linenos">162</span>                        <span class="p">[</span>
<span class="linenos">163</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
<span class="linenos">164</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
<span class="linenos">165</span>                        <span class="p">],</span>
<span class="linenos">166</span>                        <span class="p">[</span>
<span class="linenos">167</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
<span class="linenos">168</span>                            <span class="n">config</span><span class="o">.</span><span class="n">augmentation_config</span><span class="o">.</span><span class="n">translation_ranges</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">3</span><span class="p">],</span>
<span class="linenos">169</span>                        <span class="p">],</span>
<span class="linenos">170</span>                    <span class="p">),</span>
<span class="linenos">171</span>                <span class="p">],</span>
<span class="linenos">172</span>            <span class="p">],</span>
<span class="linenos">173</span>        <span class="p">),</span>
<span class="linenos">174</span>    <span class="p">]</span>
<span class="linenos">175</span>
<span class="hll"><span class="linenos">176</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">177</span>    <span class="c1"># Then, we create the actual affine transformation pipeline step. Note how multiple data fields are</span>
</span><span class="hll"><span class="linenos">178</span>    <span class="c1"># processed in the same step (images, projection matrices, point sets). All the occurences of all the data</span>
</span><span class="hll"><span class="linenos">179</span>    <span class="c1"># fields will be processed consistently, i.e. with the same transformation (could be configured to do</span>
</span><span class="hll"><span class="linenos">180</span>    <span class="c1"># otherwise by using `GroupToApplyToSelectedStepBase`-derived wrapper classes).</span>
</span><span class="linenos">181</span>    <span class="n">affine_transformer</span> <span class="o">=</span> <span class="n">AffineTransformer</span><span class="p">(</span>
<span class="linenos">182</span>        <span class="n">output_hw</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">image_config</span><span class="o">.</span><span class="n">output_hw</span><span class="p">,</span>
<span class="linenos">183</span>        <span class="n">resizing_mode</span><span class="o">=</span><span class="n">AffineTransformer</span><span class="o">.</span><span class="n">ResizingMode</span><span class="o">.</span><span class="n">PAD</span><span class="p">,</span>
<span class="linenos">184</span>        <span class="n">resizing_anchor</span><span class="o">=</span><span class="n">AffineTransformer</span><span class="o">.</span><span class="n">ResizingAnchor</span><span class="o">.</span><span class="n">CENTER</span><span class="p">,</span>
<span class="linenos">185</span>        <span class="n">image_field_names</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
<span class="linenos">186</span>        <span class="n">projection_matrix_field_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="linenos">187</span>        <span class="n">point_field_names</span><span class="o">=</span><span class="s2">&quot;bboxes&quot;</span><span class="p">,</span>
<span class="linenos">188</span>        <span class="n">transformation_steps</span><span class="o">=</span><span class="n">transformation_steps</span><span class="p">,</span>
<span class="linenos">189</span>        <span class="n">transform_image_on_gpu</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">use_device_mixed</span><span class="p">),</span>
<span class="linenos">190</span>    <span class="p">)</span>
<span class="linenos">191</span>
<span class="hll"><span class="linenos">192</span>    <span class="c1"># @NOTE: Image normalization (applied to all images with name &quot;image&quot;)</span>
</span><span class="linenos">193</span>    <span class="n">image_normalizer</span> <span class="o">=</span> <span class="n">ImageRange01Normalizer</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
<span class="linenos">194</span>
<span class="hll"><span class="linenos">195</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">196</span>    <span class="c1"># Valid annotation selection step: Create the processing step evaluating which objects are valid. Note</span>
</span><span class="hll"><span class="linenos">197</span>    <span class="c1"># that as &quot;annotation&quot; is used here as the data field group name for which the processing step is applied.</span>
</span><span class="hll"><span class="linenos">198</span>    <span class="c1"># All the names defined in the condition are expected to be children of any &quot;annotation&quot; field</span>
</span><span class="hll"><span class="linenos">199</span>    <span class="c1"># encountered in the data structure (as the step is applied to each annotation field).</span>
</span><span class="hll"><span class="linenos">200</span>    <span class="c1"># The result will also be stored as a child to the &quot;annotation&quot; fields, in this case with the name</span>
</span><span class="hll"><span class="linenos">201</span>    <span class="c1"># &quot;is_valid&quot; (defined in the condition).</span>
</span><span class="hll"><span class="linenos">202</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">203</span>    <span class="c1"># All the data fields used in the comparisons (corresponding to the names contained in the condition) will</span>
</span><span class="hll"><span class="linenos">204</span>    <span class="c1"># be deleted (as `remove_data_fields_used_in_condition=True`). This is convenient here, but in other cases</span>
</span><span class="hll"><span class="linenos">205</span>    <span class="c1"># some of the data fields may still be needed later. In that case, we can set</span>
</span><span class="hll"><span class="linenos">206</span>    <span class="c1"># `remove_data_fields_used_in_condition=False` and delete the unneeded fields manually (using</span>
</span><span class="hll"><span class="linenos">207</span>    <span class="c1"># `UnneededFieldRemover`).</span>
</span><span class="linenos">208</span>    <span class="n">valid_value_selector</span> <span class="o">=</span> <span class="n">AnnotationElementConditionEval</span><span class="p">(</span>
<span class="linenos">209</span>        <span class="n">annotation_field_name</span><span class="o">=</span><span class="s2">&quot;annotation&quot;</span><span class="p">,</span>
<span class="linenos">210</span>        <span class="n">condition</span><span class="o">=</span><span class="s2">&quot;is_valid = (num_lidar_points &gt;= 1 or num_radar_points &gt;= 1) and visibility_levels &gt; 0&quot;</span><span class="p">,</span>
<span class="linenos">211</span>        <span class="n">remove_data_fields_used_in_condition</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">212</span>    <span class="p">)</span>
<span class="linenos">213</span>
<span class="hll"><span class="linenos">214</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">215</span>    <span class="c1"># Heatmap conversion step: Generate heatmaps and related data from bounding boxes. This step expects some</span>
</span><span class="hll"><span class="linenos">216</span>    <span class="c1"># specific data fields to be available as children for each data group field with the name &quot;annotation&quot;</span>
</span><span class="hll"><span class="linenos">217</span>    <span class="c1"># in the input data.</span>
</span><span class="linenos">218</span>    <span class="n">heatmap_converter</span> <span class="o">=</span> <span class="n">BoundingBoxToHeatmapConverter</span><span class="p">(</span>
<span class="linenos">219</span>        <span class="n">image_field_name</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
<span class="linenos">220</span>        <span class="n">annotation_field_name</span><span class="o">=</span><span class="s2">&quot;annotation&quot;</span><span class="p">,</span>
<span class="linenos">221</span>        <span class="n">bboxes_in_name</span><span class="o">=</span><span class="s2">&quot;bboxes&quot;</span><span class="p">,</span>
<span class="linenos">222</span>        <span class="n">categories_in_name</span><span class="o">=</span><span class="s2">&quot;categories&quot;</span><span class="p">,</span>
<span class="linenos">223</span>        <span class="n">heatmap_out_name</span><span class="o">=</span><span class="s2">&quot;heatmap&quot;</span><span class="p">,</span>
<span class="linenos">224</span>        <span class="n">num_categories</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">heatmap_config</span><span class="o">.</span><span class="n">num_categories</span><span class="p">,</span>
<span class="linenos">225</span>        <span class="n">heatmap_hw</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">heatmap_config</span><span class="o">.</span><span class="n">heatmap_hw</span><span class="p">,</span>
<span class="linenos">226</span>        <span class="n">is_valid_opt_in_name</span><span class="o">=</span><span class="s2">&quot;is_valid&quot;</span><span class="p">,</span>
<span class="linenos">227</span>        <span class="n">center_opt_in_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Compute the center from the bounding box.</span>
<span class="linenos">228</span>        <span class="n">is_active_opt_out_name</span><span class="o">=</span><span class="s2">&quot;is_active&quot;</span><span class="p">,</span>
<span class="linenos">229</span>        <span class="n">center_opt_out_name</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
<span class="linenos">230</span>        <span class="n">center_offset_opt_out_name</span><span class="o">=</span><span class="s2">&quot;center_offset&quot;</span><span class="p">,</span>
<span class="linenos">231</span>        <span class="n">height_width_bboxes_heatmap_opt_out_name</span><span class="o">=</span><span class="s2">&quot;height_width_bboxes_heatmap&quot;</span><span class="p">,</span>
<span class="linenos">232</span>        <span class="n">bboxes_heatmap_opt_out_name</span><span class="o">=</span><span class="s2">&quot;bboxes_heatmap&quot;</span><span class="p">,</span>
<span class="linenos">233</span>        <span class="n">max_radius</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">heatmap_config</span><span class="o">.</span><span class="n">max_radius</span><span class="p">,</span>
<span class="linenos">234</span>    <span class="p">)</span>
<span class="linenos">235</span>
<span class="hll"><span class="linenos">236</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">237</span>    <span class="c1"># Cleanup step: This processing step does not perform any actual computations. It is instead responsible</span>
</span><span class="hll"><span class="linenos">238</span>    <span class="c1"># for removing unneeded fields from the input data structure. The fields with the given names are removed</span>
</span><span class="hll"><span class="linenos">239</span>    <span class="c1"># no matter where in the input data structure they appear.</span>
</span><span class="hll"><span class="linenos">240</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">241</span>    <span class="c1"># This is done here as they are not needed anymore and outputting them from the pipeline would potentially</span>
</span><span class="hll"><span class="linenos">242</span>    <span class="c1"># lead to unneccesary copies (to make the individual samples continuous in memory). Note that this step is</span>
</span><span class="hll"><span class="linenos">243</span>    <span class="c1"># completely performed at the pipeline construction (i.e. DALI graph construction time), and does not add</span>
</span><span class="hll"><span class="linenos">244</span>    <span class="c1"># any runtime overhead when running the pipeline.</span>
</span><span class="linenos">245</span>    <span class="n">unneeded_fields_remover</span> <span class="o">=</span> <span class="n">UnneededFieldRemover</span><span class="p">([</span><span class="s2">&quot;image_hw&quot;</span><span class="p">,</span> <span class="s2">&quot;is_valid&quot;</span><span class="p">])</span>
<span class="linenos">246</span>
<span class="hll"><span class="linenos">247</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">248</span>    <span class="c1"># Pad all children of data group fields with the name &quot;annotation&quot;.</span>
</span><span class="hll"><span class="linenos">249</span>    <span class="c1"># Note that the padding is performed only to the annotations:</span>
</span><span class="hll"><span class="linenos">250</span>    <span class="c1">#   - As it is known that non-uniform sizes are only present there, so no need to check other fields</span>
</span><span class="hll"><span class="linenos">251</span>    <span class="c1">#   - As this step expects all contained data to be non-scalar, and thus, care must be taken that no</span>
</span><span class="hll"><span class="linenos">252</span>    <span class="c1">#     scalar data fields are present.</span>
</span><span class="linenos">253</span>    <span class="n">padding_to_uniform</span> <span class="o">=</span> <span class="n">PaddingToUniform</span><span class="p">(</span><span class="n">field_names</span><span class="o">=</span><span class="s2">&quot;annotation&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="linenos">254</span>
<span class="hll"><span class="linenos">255</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">256</span>    <span class="c1"># Store the steps as a sequence in the order in which they are going to be processed by the pipeline. Note</span>
</span><span class="hll"><span class="linenos">257</span>    <span class="c1"># that that &#39;image_normalizer&#39; is an optional step. If it is not needed, &#39;None&#39; is used instead. This is</span>
</span><span class="hll"><span class="linenos">258</span>    <span class="c1"># interpreted by the pipeline as a no-op and is ignored.</span>
</span><span class="linenos">259</span>    <span class="n">pre_processing_steps</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos">260</span>        <span class="n">decoder</span><span class="p">,</span>
<span class="linenos">261</span>        <span class="n">affine_transformer</span><span class="p">,</span>
<span class="linenos">262</span>        <span class="p">(</span><span class="n">image_normalizer</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">image_config</span><span class="o">.</span><span class="n">normalize</span> <span class="k">else</span> <span class="kc">None</span><span class="p">),</span>
<span class="linenos">263</span>        <span class="n">valid_value_selector</span><span class="p">,</span>
<span class="linenos">264</span>        <span class="n">heatmap_converter</span><span class="p">,</span>
<span class="linenos">265</span>        <span class="n">unneeded_fields_remover</span><span class="p">,</span>
<span class="linenos">266</span>        <span class="n">padding_to_uniform</span><span class="p">,</span>
<span class="linenos">267</span>    <span class="p">]</span>
<span class="linenos">268</span>
</pre></div>
</div>
</div>
</section>
<section id="pipeline-definition-output-data-structure-blueprint">
<h3>Pipeline Definition &amp; Output Data Structure Blueprint<a class="headerlink" href="#pipeline-definition-output-data-structure-blueprint" title="Link to this heading"></a></h3>
<p>The pipeline definition wires the input callable with the processing steps. It also provides utilities
such as obtaining the output data structure blueprint (see
<a class="reference internal" href="../../api/pipeline.html#accvlab.dali_pipeline_framework.pipeline.PipelineDefinition.check_and_get_output_data_structure" title="accvlab.dali_pipeline_framework.pipeline.PipelineDefinition.check_and_get_output_data_structure"><code class="xref py py-meth docutils literal notranslate"><span class="pre">check_and_get_output_data_structure()</span></code></a>), which
we use here.</p>
<p>The output blueprint captures the hierarchical structure and types of the pipeline output.
It is later used to reconstruct structured samples from flat DALI outputs.</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/object_detection_2d_pipeline.py</span><a class="headerlink" href="#id3" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">269</span>    <span class="c1"># ===== Pipeline definition &amp; Output data format =====</span>
<span class="hll"><span class="linenos">270</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">271</span>    <span class="c1"># Define the pipeline consisting of the &#39;input_callable&#39; and &#39;pre_processing_steps&#39;.</span>
</span><span class="hll"><span class="linenos">272</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">273</span>    <span class="c1"># IMPORTANT: Note how `check_data_format` is set to `False` here. This is done to avoid the overhead of</span>
</span><span class="hll"><span class="linenos">274</span>    <span class="c1"># checking the data format during pipeline execution. During development, it is recommended to set it</span>
</span><span class="hll"><span class="linenos">275</span>    <span class="c1"># to `True` to catch potential issues early, and later set it to `False` to avoid the overhead in</span>
</span><span class="hll"><span class="linenos">276</span>    <span class="c1"># production.</span>
</span><span class="linenos">277</span>    <span class="n">pipeline_def</span> <span class="o">=</span> <span class="n">PipelineDefinition</span><span class="p">(</span>
<span class="linenos">278</span>        <span class="n">input_callable</span><span class="p">,</span> <span class="n">pre_processing_steps</span><span class="p">,</span> <span class="n">check_data_format</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">print_sample_data_group_format</span><span class="o">=</span><span class="kc">True</span>
<span class="linenos">279</span>    <span class="p">)</span>
<span class="linenos">280</span>
<span class="hll"><span class="linenos">281</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">282</span>    <span class="c1"># This is the output data format blueprint (also documentation of `SampleDataGroup` for a description of</span>
</span><span class="hll"><span class="linenos">283</span>    <span class="c1"># the blueprint concept). This means it is a `SampleDataGroup` with the data format as the actual output</span>
</span><span class="hll"><span class="linenos">284</span>    <span class="c1"># (i.e. same (nested) data group fields &amp; data fields, data types), but without the actual data. As the</span>
</span><span class="hll"><span class="linenos">285</span>    <span class="c1"># output of the pipeline will be flattened into a sequence, this blueprint can be used to fill it back to</span>
</span><span class="hll"><span class="linenos">286</span>    <span class="c1"># the hierarchical `SampleDataGroup` structure.</span>
</span><span class="linenos">287</span>    <span class="n">res_data_setup</span> <span class="o">=</span> <span class="n">pipeline_def</span><span class="o">.</span><span class="n">check_and_get_output_data_structure</span><span class="p">()</span>
<span class="linenos">288</span>
</pre></div>
</div>
</div>
</section>
<section id="create-and-build-the-dali-pipeline">
<h3>Create and Build the DALI Pipeline<a class="headerlink" href="#create-and-build-the-dali-pipeline" title="Link to this heading"></a></h3>
<p>The concrete DALI pipeline can be created using the pipeline definition and configured similar to how
it is done for a standalone DALI pipeline.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/object_detection_2d_pipeline.py</span><a class="headerlink" href="#id4" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">289</span>    <span class="c1"># ===== Create DALI pipeline =====</span>
<span class="hll"><span class="linenos">290</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">291</span>    <span class="c1"># Set a pre-defined seed used in augmentation if the results need to be repeatable. Note that the seed is</span>
</span><span class="hll"><span class="linenos">292</span>    <span class="c1"># different for each GPU (rank) in case of multi-GPU training to avoid performing the exact same</span>
</span><span class="hll"><span class="linenos">293</span>    <span class="c1"># augmentations. A value of -1 means a unique seed will be used every time.</span>
</span><span class="hll"><span class="linenos">294</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">295</span>    <span class="c1"># This is different from the shuffling seed, which needs to be the same for all GPUs to enable consistent</span>
</span><span class="hll"><span class="linenos">296</span>    <span class="c1"># sharding.</span>
</span><span class="linenos">297</span>    <span class="k">if</span> <span class="n">repeatable_seed</span><span class="p">:</span>
<span class="linenos">298</span>        <span class="n">seed</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span>
<span class="linenos">299</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos">300</span>        <span class="n">seed</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="linenos">301</span>
<span class="linenos">302</span>    <span class="c1"># Start measuring the time for creating the pipeline.</span>
<span class="linenos">303</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">start_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_create&quot;</span><span class="p">)</span>
<span class="linenos">304</span>
<span class="hll"><span class="linenos">305</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">306</span>    <span class="c1"># This step is for obtaining the actual DALI Pipeline object (see DALI getting started tutorial:</span>
</span><span class="hll"><span class="linenos">307</span>    <span class="c1"># https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/getting_started.html)</span>
</span><span class="linenos">308</span>    <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline_def</span><span class="o">.</span><span class="n">get_dali_pipeline</span><span class="p">(</span>
<span class="linenos">309</span>        <span class="n">enable_conditionals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">310</span>        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span class="linenos">311</span>        <span class="n">prefetch_queue_depth</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">pipeline_config</span><span class="o">.</span><span class="n">prefetch_queue_depth</span><span class="p">,</span>
<span class="linenos">312</span>        <span class="n">py_num_workers</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">pipeline_config</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
<span class="linenos">313</span>        <span class="n">py_start_method</span><span class="o">=</span><span class="s2">&quot;spawn&quot;</span><span class="p">,</span>
<span class="linenos">314</span>        <span class="n">num_threads</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">pipeline_config</span><span class="o">.</span><span class="n">num_threads</span><span class="p">,</span>
<span class="linenos">315</span>        <span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span> <span class="k">if</span> <span class="n">use_gpu</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos">316</span>        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
<span class="linenos">317</span>    <span class="p">)</span>
<span class="linenos">318</span>
<span class="linenos">319</span>    <span class="c1"># End measuring the time for creating the pipeline.</span>
<span class="linenos">320</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">end_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_create&quot;</span><span class="p">)</span>
<span class="linenos">321</span>
<span class="linenos">322</span>    <span class="c1"># Start measuring the time for building the pipeline.</span>
<span class="linenos">323</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">start_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_build&quot;</span><span class="p">)</span>
<span class="linenos">324</span>
<span class="hll"><span class="linenos">325</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">326</span>    <span class="c1"># For details on preparing the pipeline see:</span>
</span><span class="hll"><span class="linenos">327</span>    <span class="c1"># case spawn:</span>
</span><span class="hll"><span class="linenos">328</span>    <span class="c1"># https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/general/data_loading/parallel_external_source.html</span>
</span><span class="hll"><span class="linenos">329</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">330</span>    <span class="c1"># case fork:</span>
</span><span class="hll"><span class="linenos">331</span>    <span class="c1"># https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/general/data_loading/parallel_external_source_fork.html</span>
</span><span class="linenos">332</span>    <span class="n">pipe</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="linenos">333</span>
<span class="linenos">334</span>    <span class="c1"># End measuring the time for building the pipeline.</span>
<span class="linenos">335</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">end_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_build&quot;</span><span class="p">)</span>
<span class="linenos">336</span>
<span class="linenos">337</span>    <span class="c1"># Print the times.</span>
<span class="linenos">338</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">print_eval_times</span><span class="p">()</span>
<span class="linenos">339</span>
</pre></div>
</div>
</div>
</section>
<section id="wrap-as-structured-iterator-return">
<h3>Wrap as Structured Iterator &amp; Return<a class="headerlink" href="#wrap-as-structured-iterator-return" title="Link to this heading"></a></h3>
<p>The DALI pipeline is wrapped as a <code class="docutils literal notranslate"><span class="pre">DALIStructuredOutputIterator</span></code> that can be used as a
drop-in replacement for a PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/object_detection_2d_pipeline.py</span><a class="headerlink" href="#id5" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">340</span>    <span class="c1"># ===== Wrap as iterator =====</span>
<span class="hll"><span class="linenos">341</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">342</span>    <span class="c1"># Wrap the pipeline as an DALIStructuredOutputIterator, which can be used as a drop-in replacement for a</span>
</span><span class="hll"><span class="linenos">343</span>    <span class="c1"># PyTorch DataLoader.</span>
</span><span class="hll"><span class="linenos">344</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">345</span>    <span class="c1"># Note that apart from the pipeline, the info on the epoch size and the data format of the output</span>
</span><span class="hll"><span class="linenos">346</span>    <span class="c1"># (`res_data_setup`) need to be set explicitly in the iterator wrapper.</span>
</span><span class="hll"><span class="linenos">347</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">348</span>    <span class="c1"># Also, we use the `CreateAsDataLoaderObject()` method rather than the constructor directly. This ensures</span>
</span><span class="hll"><span class="linenos">349</span>    <span class="c1"># that the iterator object is masked as a PyTorch DataLoader object, so that checks such as</span>
</span><span class="hll"><span class="linenos">350</span>    <span class="c1"># `assert isinstance(iterator_object, DataLoader)` pass.</span>
</span><span class="linenos">351</span>    <span class="n">res_iterator</span> <span class="o">=</span> <span class="n">DALIStructuredOutputIterator</span><span class="o">.</span><span class="n">CreateAsDataLoaderObject</span><span class="p">(</span>
<span class="linenos">352</span>        <span class="n">input_callable</span><span class="o">.</span><span class="n">length</span><span class="p">,</span> <span class="n">pipe</span><span class="p">,</span> <span class="n">res_data_setup</span>
<span class="linenos">353</span>    <span class="p">)</span>
<span class="linenos">354</span>
<span class="linenos">355</span>    <span class="k">return</span> <span class="n">res_iterator</span>
</pre></div>
</div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For an example using sequence-based sampling and multi-task learning (3D object detection with auxiliary
2D object detection) see <a class="reference internal" href="../stream_petr/index.html"><span class="doc">StreamPETR Pipeline</span></a>.</p>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="2D Object Detection Pipeline" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../stream_petr/index.html" class="btn btn-neutral float-right" title="StreamPETR Pipeline" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>