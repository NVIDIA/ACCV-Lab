

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>StreamPETR Pipeline Setup &mdash; ACCV-Lab 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/custom.css?v=9282052d" />

  
      <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="Custom Processing Step: StreamPETRDataCombiner" href="custom_processing_step.html" />
    <link rel="prev" title="StreamPETR Pipeline" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            ACCV-Lab
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">General Info</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../project_overview/README.html">ACCV-Lab Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../guides_index.html">Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contained Packages</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../on_demand_video_decoder/docs/index.html">On Demand Video Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../batching_helpers/docs/index.html">Batching Helpers</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">DALI Pipeline Framework</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../design.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/main_api.html">Main API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/additional_api.html">Additional API Reference</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../examples.html">Examples</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../examples.html#pipeline-setup-examples">Pipeline Setup Examples</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../2d_object_detection/index.html">2D Object Detection Pipeline</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html">StreamPETR Pipeline</a><ul class="current">
<li class="toctree-l5 current"><a class="current reference internal" href="#">StreamPETR Pipeline Setup</a></li>
<li class="toctree-l5"><a class="reference internal" href="custom_processing_step.html">Custom Processing Step: <code class="docutils literal notranslate"><span class="pre">StreamPETRDataCombiner</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="custom_post_processing.html">Custom Post-Processing</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../flexible_step/index.html">Flexible Step Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../examples.html#data-loaders-for-nuscenes">Data Loaders for NuScenes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../evaluation.html">Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../draw_heatmap/docs/index.html">Draw Heatmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim_test_tools/docs/index.html">Optimization Testing Tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">ACCV-Lab</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">DALI Pipeline Framework</a></li>
          <li class="breadcrumb-item"><a href="../../examples.html">Examples</a></li>
          <li class="breadcrumb-item"><a href="index.html">StreamPETR Pipeline</a></li>
      <li class="breadcrumb-item active">StreamPETR Pipeline Setup</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/contained_package_docs_mirror/dali_pipeline_framework/docs/examples/stream_petr/pipeline_setup.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="streampetr-pipeline-setup">
<h1>StreamPETR Pipeline Setup<a class="headerlink" href="#streampetr-pipeline-setup" title="Link to this heading"></a></h1>
<p>This page documents the DALI-based StreamPETR training pipeline as implemented in
<code class="docutils literal notranslate"><span class="pre">examples/pipeline_setup/stream_petr_pipeline.py</span></code>.</p>
<section id="overview-and-goals">
<h2>Overview and Goals<a class="headerlink" href="#overview-and-goals" title="Link to this heading"></a></h2>
<div class="docutils container">
<p>StreamPETR training pipeline using DALI.</p>
<p>This pipeline reads NuScenes samples in a sequence-based way, applies image decoding and augmentations,
filters and prepares both 2D and 3D ground-truth annotations, and converts outputs into the
training format expected by StreamPETR via a dedicated post-processing function.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>Please also see <a class="reference internal" href="../2d_object_detection/pipeline_setup.html"><span class="doc">2D Object Detection Pipeline Setup</span></a>. Here, we assume that the reader is familiar
with that example and refer to it for some details which apply to both pipelines.</p>
</div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The pipeline described here is designed as a drop-in replacement for the PyTorch DataLoader
which can be used for the training of the
<a class="reference external" href="https://github.com/exiawsh/StreamPETR">original StreamPETR implementation</a> in the
<strong>streaming video training mode</strong> (<code class="docutils literal notranslate"><span class="pre">seq_mode=True</span></code>).
Therefore, we implement the pipeline in a way that the final output data structure (of the
<a class="reference internal" href="../../api/pipeline.html#accvlab.dali_pipeline_framework.pipeline.DALIStructuredOutputIterator" title="accvlab.dali_pipeline_framework.pipeline.DALIStructuredOutputIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">DALIStructuredOutputIterator</span></code></a> object wrapping the
pipeline) is compatible with the output data structure of the PyTorch DataLoader in the original
implementation and contains all the data needed for training in the expected format.</p>
</div>
</section>
<section id="details">
<h2>Details<a class="headerlink" href="#details" title="Link to this heading"></a></h2>
<p>Here, we discuss the details of the <code class="docutils literal notranslate"><span class="pre">StreamPETR</span></code> pipeline setup.</p>
<section id="input-data-handling">
<h3>Input Data Handling<a class="headerlink" href="#input-data-handling" title="Link to this heading"></a></h3>
<p>Here, we use a <a class="reference internal" href="../../api/inputs.html#accvlab.dali_pipeline_framework.inputs.SequenceSampler" title="accvlab.dali_pipeline_framework.inputs.SequenceSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceSampler</span></code></a> to load sequence-based data.
When loading the data, we also perform some simple high-level pre-processing of the metadata, such as scene
filtering and sequence splitting.</p>
<p>See the <a class="reference internal" href="../2d_object_detection/pipeline_setup.html"><span class="doc">2D Object Detection Pipeline Setup</span></a> for general input callable mechanics as well as
sharding/shuffling.</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/stream_petr_pipeline.py</span><a class="headerlink" href="#id1" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">284</span>    <span class="c1"># ===== Input data handling =====</span>
<span class="linenos">285</span>
<span class="hll"><span class="linenos">286</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">287</span>    <span class="c1"># Goal: Create an input implementation (iterable or callable) that provides sequence-based samples for</span>
</span><span class="hll"><span class="linenos">288</span>    <span class="c1"># StreamPETR. See the 2D object detection example for general input callable mechanics and</span>
</span><span class="hll"><span class="linenos">289</span>    <span class="c1"># sharding/shuffling notes.</span>
</span><span class="linenos">290</span>
<span class="hll"><span class="linenos">291</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">292</span>    <span class="c1"># Try to load previously converted data. If this is not possible, read in the original format &amp; convert.</span>
</span><span class="linenos">293</span>    <span class="n">nuscenes_preproc_file_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">_preproc_</span><span class="si">{}</span><span class="s1">.pkl&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nuscenes_version</span><span class="p">,</span> <span class="s2">&quot;streampetr&quot;</span><span class="p">)</span>
<span class="linenos">294</span>    <span class="n">input_data</span> <span class="o">=</span> <span class="n">NuScenesReader</span><span class="o">.</span><span class="n">load_data_if_available_else_create_and_store</span><span class="p">(</span>
<span class="linenos">295</span>        <span class="n">nuscenes_root_dir</span><span class="p">,</span>
<span class="linenos">296</span>        <span class="n">nuscenes_preproc_file_name</span><span class="p">,</span>
<span class="linenos">297</span>        <span class="n">nuscenes_version</span><span class="p">,</span>
<span class="linenos">298</span>        <span class="n">add_projected_bboxes_annotations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">299</span>        <span class="n">image_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">image_size</span><span class="p">,</span>
<span class="linenos">300</span>    <span class="p">)</span>
<span class="linenos">301</span>
<span class="hll"><span class="linenos">302</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">303</span>    <span class="c1"># Remove dedicated validation scenes and perform basic dataset reshaping (sort, split sequences) for</span>
</span><span class="hll"><span class="linenos">304</span>    <span class="c1"># training.</span>
</span><span class="linenos">305</span>    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">get_subset_without_sequences</span><span class="p">(</span><span class="n">val_sequences</span><span class="p">)</span>
<span class="linenos">306</span>    <span class="c1"># Sort scenes by timestamps</span>
<span class="linenos">307</span>    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">get_sequences_sorted_by_start_time</span><span class="p">()</span>
<span class="linenos">308</span>    <span class="c1"># Split each scene into 2 sequences. This increases the number of sequences, and is also done in the</span>
<span class="linenos">309</span>    <span class="c1"># original StreamPETR pipeline.</span>
<span class="linenos">310</span>    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">get_with_sequences_split</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos">311</span>
<span class="hll"><span class="linenos">312</span>    <span class="c1"># @NOTE Create a data provider for the StreamPETR use-case.</span>
</span><span class="linenos">313</span>    <span class="n">input_provider</span> <span class="o">=</span> <span class="n">NuscenesStreamPETRDataProvider</span><span class="p">(</span>
<span class="linenos">314</span>        <span class="n">nuscenes_root_dir</span><span class="p">,</span>
<span class="linenos">315</span>        <span class="n">input_data</span><span class="p">,</span>
<span class="linenos">316</span>        <span class="n">image_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">image_size</span><span class="p">,</span>
<span class="linenos">317</span>        <span class="n">return_ground_truth</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">318</span>    <span class="p">)</span>
<span class="linenos">319</span>
<span class="hll"><span class="linenos">320</span>    <span class="c1"># @NOTE Total batch size for multi-GPU training (used by the sampler).</span>
</span><span class="linenos">321</span>    <span class="n">total_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">world_size</span>
<span class="hll"><span class="linenos">322</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">323</span>    <span class="c1"># Sampler defines per-batch sequence indices; can randomize selection based on config.</span>
</span><span class="hll"><span class="linenos">324</span>    <span class="c1"># Note that `input_data.get_sequence_lengths()` is used to get the sequence lengths, so that the sampler</span>
</span><span class="hll"><span class="linenos">325</span>    <span class="c1"># knows how the dataset is divided into the individual sequences.</span>
</span><span class="linenos">326</span>    <span class="n">sequence_sampler</span> <span class="o">=</span> <span class="n">SequenceSampler</span><span class="p">(</span>
<span class="linenos">327</span>        <span class="n">total_batch_size</span><span class="p">,</span> <span class="n">input_data</span><span class="o">.</span><span class="n">get_sequence_lengths</span><span class="p">(),</span> <span class="mi">21</span><span class="p">,</span> <span class="n">randomize</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">randomize_sample_selection</span>
<span class="linenos">328</span>    <span class="p">)</span>
<span class="hll"><span class="linenos">329</span>    <span class="c1"># @NOTE Create either an input iterable or input callable using the sampler and data provider.</span>
</span><span class="linenos">330</span>    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">use_input_iterable</span><span class="p">:</span>
<span class="linenos">331</span>        <span class="n">input_impl</span> <span class="o">=</span> <span class="n">SamplerInputIterable</span><span class="p">(</span><span class="n">input_provider</span><span class="p">,</span> <span class="n">sequence_sampler</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
<span class="linenos">332</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos">333</span>        <span class="n">input_impl</span> <span class="o">=</span> <span class="n">SamplerInputCallable</span><span class="p">(</span>
<span class="linenos">334</span>            <span class="n">input_provider</span><span class="p">,</span>
<span class="linenos">335</span>            <span class="n">sequence_sampler</span><span class="p">,</span>
<span class="linenos">336</span>            <span class="n">config</span><span class="o">.</span><span class="n">max_iterations_input_callable</span><span class="p">,</span>
<span class="linenos">337</span>            <span class="n">config</span><span class="o">.</span><span class="n">prefetch_queue_depth</span><span class="p">,</span>
<span class="linenos">338</span>            <span class="n">rank</span><span class="p">,</span>
<span class="linenos">339</span>            <span class="n">world_size</span><span class="p">,</span>
<span class="linenos">340</span>        <span class="p">)</span>
<span class="linenos">341</span>
</pre></div>
</div>
</div>
</section>
<section id="define-processing-steps">
<h3>Define Processing Steps<a class="headerlink" href="#define-processing-steps" title="Link to this heading"></a></h3>
<p>Here, we define the pre-processing steps that will be applied to the input data.</p>
<p>The processing is more involved than in the <a class="reference internal" href="../2d_object_detection/pipeline_setup.html"><span class="doc">2D Object Detection Pipeline Setup</span></a>. Please see the
code below, and refer to <a class="reference internal" href="../2d_object_detection/pipeline_setup.html"><span class="doc">2D Object Detection Pipeline Setup</span></a> for more details on some of the steps.</p>
<p>Also note that this pipeline uses a custom step to combine and format the data to a format close to StreamPETR
training expectations; see <a class="reference internal" href="custom_processing_step.html"><span class="doc">Custom Processing Step: StreamPETRDataCombiner</span></a> for details.</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/stream_petr_pipeline.py</span><a class="headerlink" href="#id2" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">342</span>    <span class="c1"># ===== Define processing steps =====</span>
<span class="hll"><span class="linenos">343</span>    <span class="c1"># @NOTE The following pre-processing steps mirror the 2D object detection example in spirit, adapted to</span>
</span><span class="hll"><span class="linenos">344</span>    <span class="c1"># StreamPETR specifics. Refer to the 2D object detection example for details on common concepts</span>
</span><span class="hll"><span class="linenos">345</span>    <span class="c1"># (e.g. name-based data selection, optional steps, padding, etc.).</span>
</span><span class="linenos">346</span>
<span class="linenos">347</span>    <span class="n">decoder</span> <span class="o">=</span> <span class="n">ImageDecoder</span><span class="p">(</span>
<span class="linenos">348</span>        <span class="s2">&quot;image&quot;</span><span class="p">,</span>
<span class="linenos">349</span>        <span class="n">use_device_mixed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">350</span>        <span class="n">hw_decoder_load</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">hw_decoder_load</span><span class="p">,</span>
<span class="linenos">351</span>        <span class="n">as_bgr</span><span class="o">=</span><span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">as_rgb</span><span class="p">,</span>
<span class="linenos">352</span>    <span class="p">)</span>
<span class="linenos">353</span>
<span class="hll"><span class="linenos">354</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">355</span>    <span class="c1"># Affine augmentation: define the sequence of transforms (flip, scaling, alignment) and then create the</span>
</span><span class="hll"><span class="linenos">356</span>    <span class="c1"># step.</span>
</span><span class="linenos">357</span>    <span class="n">image_flip_prob</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">affine_trafo_config</span><span class="o">.</span><span class="n">rand_flip</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="linenos">358</span>    <span class="n">transformation_steps</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos">359</span>        <span class="c1"># Perform a horizontal image flip (i.e. scale along the x-axis with a fixed factor of -1.0, and a</span>
<span class="linenos">360</span>        <span class="c1"># factor of 1.0 (i.e. unchanged) for the y-axis) with a probability of 0.5 if random flips are enabled</span>
<span class="linenos">361</span>        <span class="c1"># in the configuration, and with a probability of 0.0 otherwise</span>
<span class="linenos">362</span>        <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">NonUniformScaling</span><span class="p">(</span><span class="n">image_flip_prob</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span>
<span class="linenos">363</span>        <span class="c1"># Scaling in a configured range</span>
<span class="linenos">364</span>        <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">UniformScaling</span><span class="p">(</span>
<span class="linenos">365</span>            <span class="mf">1.0</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">affine_trafo_config</span><span class="o">.</span><span class="n">resize_lim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">config</span><span class="o">.</span><span class="n">affine_trafo_config</span><span class="o">.</span><span class="n">resize_lim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos">366</span>        <span class="p">),</span>
<span class="linenos">367</span>        <span class="c1"># NOTE</span>
<span class="linenos">368</span>        <span class="c1"># Align bottom border of the viewport with the original image. Note that such alignment operations are</span>
<span class="linenos">369</span>        <span class="c1"># also part of the `AffineTransformer` step (and not only random augmentations).</span>
<span class="linenos">370</span>        <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">ShiftToAlignWithOriginalImageBorder</span><span class="p">(</span>
<span class="linenos">371</span>            <span class="mf">1.0</span><span class="p">,</span> <span class="n">AffineTransformer</span><span class="o">.</span><span class="n">ShiftToAlignWithOriginalImageBorder</span><span class="o">.</span><span class="n">Border</span><span class="o">.</span><span class="n">BOTTOM</span>
<span class="linenos">372</span>        <span class="p">),</span>
<span class="linenos">373</span>    <span class="p">]</span>
<span class="hll"><span class="linenos">374</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">375</span>    <span class="c1"># Create the actual affine transformation step. Apart from the affine transformation itself, the step</span>
</span><span class="hll"><span class="linenos">376</span>    <span class="c1"># additionally applies resizing to needed output image size and ensures that the image remains aligned</span>
</span><span class="hll"><span class="linenos">377</span>    <span class="c1"># to the bottom border of the viewport, cropping on the top if needed.</span>
</span><span class="linenos">378</span>    <span class="n">image_trafo</span> <span class="o">=</span> <span class="n">AffineTransformer</span><span class="p">(</span>
<span class="linenos">379</span>        <span class="n">output_hw</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">affine_trafo_config</span><span class="o">.</span><span class="n">output_hw</span><span class="p">,</span>
<span class="linenos">380</span>        <span class="n">resizing_mode</span><span class="o">=</span><span class="n">AffineTransformer</span><span class="o">.</span><span class="n">ResizingMode</span><span class="o">.</span><span class="n">CROP</span><span class="p">,</span>
<span class="linenos">381</span>        <span class="n">resizing_anchor</span><span class="o">=</span><span class="n">AffineTransformer</span><span class="o">.</span><span class="n">ResizingAnchor</span><span class="o">.</span><span class="n">BOTTOM_OR_RIGHT</span><span class="p">,</span>
<span class="linenos">382</span>        <span class="n">image_field_names</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
<span class="linenos">383</span>        <span class="n">projection_matrix_field_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lidar2img&quot;</span><span class="p">,</span> <span class="s2">&quot;intr_lidar2img&quot;</span><span class="p">],</span>
<span class="linenos">384</span>        <span class="n">point_field_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;centers&quot;</span><span class="p">,</span> <span class="s2">&quot;bboxes&quot;</span><span class="p">],</span>
<span class="linenos">385</span>        <span class="n">transformation_steps</span><span class="o">=</span><span class="n">transformation_steps</span><span class="p">,</span>
<span class="linenos">386</span>        <span class="n">transform_image_on_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">387</span>    <span class="p">)</span>
<span class="hll"><span class="linenos">388</span>    <span class="c1"># @NOTE Pad images so width/height are divisible by 32 (as expected by training implementation).</span>
</span><span class="linenos">389</span>    <span class="n">image_padder</span> <span class="o">=</span> <span class="n">ImageToTileSizePadder</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="hll"><span class="linenos">390</span>    <span class="c1"># @NOTE Normalize images based on pre-defined mean &amp; std.dev. values.</span>
</span><span class="linenos">391</span>    <span class="n">normalizer</span> <span class="o">=</span> <span class="n">ImageMeanStdDevNormalizer</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">img_norm_cfg</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">img_norm_cfg</span><span class="o">.</span><span class="n">std</span><span class="p">)</span>
<span class="linenos">392</span>
<span class="hll"><span class="linenos">393</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">394</span>    <span class="c1"># Select visible 2D bboxes (not completely occluded by closer bboxes and not too small)</span>
</span><span class="hll"><span class="linenos">395</span>    <span class="c1"># Note that this step is applied per camera, as it expects to find exactly one data field for each</span>
</span><span class="hll"><span class="linenos">396</span>    <span class="c1"># role (e.g. bonuding boxes, depths etc.), so that the correspondences between these fields are clear.</span>
</span><span class="linenos">397</span>    <span class="n">visible_bbox_selector_per_cam</span> <span class="o">=</span> <span class="n">VisibleBboxSelector</span><span class="p">(</span>
<span class="linenos">398</span>        <span class="s2">&quot;bboxes&quot;</span><span class="p">,</span>
<span class="linenos">399</span>        <span class="n">resulting_mask_field_path</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;gt_boxes_2d&quot;</span><span class="p">,</span> <span class="s2">&quot;is_visible&quot;</span><span class="p">),</span>
<span class="linenos">400</span>        <span class="n">image_field_name</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
<span class="linenos">401</span>        <span class="n">check_for_bbox_occlusion</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">402</span>        <span class="n">check_for_minimum_size</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">403</span>        <span class="n">depths_field_name</span><span class="o">=</span><span class="s2">&quot;depths&quot;</span><span class="p">,</span>
<span class="linenos">404</span>        <span class="n">minimum_bbox_size</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
<span class="linenos">405</span>    <span class="p">)</span>
<span class="hll"><span class="linenos">406</span>    <span class="c1"># @NOTE Ensure the step is applied per camera using an access modifier wrapper step.</span>
</span><span class="linenos">407</span>    <span class="n">visible_bbox_selector</span> <span class="o">=</span> <span class="n">DataGroupArrayWithNameElementsAppliedStep</span><span class="p">(</span><span class="n">visible_bbox_selector_per_cam</span><span class="p">,</span> <span class="s2">&quot;cams&quot;</span><span class="p">)</span>
<span class="linenos">408</span>
<span class="hll"><span class="linenos">409</span>    <span class="c1"># @NOTE Check whether 3D bbox centers are within a configured range.</span>
</span><span class="linenos">410</span>    <span class="n">point_cloud_range_min</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">point_cloud_range</span><span class="o">.</span><span class="n">min</span>
<span class="linenos">411</span>    <span class="n">point_cloud_range_max</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">point_cloud_range</span><span class="o">.</span><span class="n">max</span>
<span class="hll"><span class="linenos">412</span>    <span class="c1"># @NOTE None denotes no border → replaced by -inf/inf for computation.</span>
</span><span class="linenos">413</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
<span class="linenos">414</span>        <span class="k">if</span> <span class="n">point_cloud_range_min</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">415</span>            <span class="n">point_cloud_range_min</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="linenos">416</span>        <span class="k">if</span> <span class="n">point_cloud_range_max</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">417</span>            <span class="n">point_cloud_range_max</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="linenos">418</span>    <span class="n">bbox_inside_range_selector</span> <span class="o">=</span> <span class="n">PointsInRangeCheck</span><span class="p">(</span>
<span class="linenos">419</span>        <span class="s2">&quot;translations&quot;</span><span class="p">,</span> <span class="s2">&quot;is_bbox_in_range&quot;</span><span class="p">,</span> <span class="n">point_cloud_range_min</span><span class="p">,</span> <span class="n">point_cloud_range_max</span>
<span class="linenos">420</span>    <span class="p">)</span>
<span class="linenos">421</span>
<span class="hll"><span class="linenos">422</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">423</span>    <span class="c1"># Mark active objects (3D) based on multi-sensor evidence and range checks; keep inputs for later steps.</span>
</span><span class="hll"><span class="linenos">424</span>    <span class="c1"># Please see the 2D object detection example for more details on the `AnnotationElementConditionEval` step.</span>
</span><span class="linenos">425</span>    <span class="n">active_value_selector</span> <span class="o">=</span> <span class="n">AnnotationElementConditionEval</span><span class="p">(</span>
<span class="linenos">426</span>        <span class="s2">&quot;gt_boxes&quot;</span><span class="p">,</span>
<span class="linenos">427</span>        <span class="n">condition</span><span class="o">=</span><span class="s2">&quot;is_active = (num_lidar_points &gt;= 1 or num_radar_points &gt;= 1) and categories &gt;= 0 and is_bbox_in_range&quot;</span><span class="p">,</span>
<span class="linenos">428</span>        <span class="n">remove_data_fields_used_in_condition</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">429</span>    <span class="p">)</span>
<span class="linenos">430</span>
<span class="hll"><span class="linenos">431</span>    <span class="c1"># @NOTE Mark active objects (2D) using category and visibility flags from the previous step.</span>
</span><span class="linenos">432</span>    <span class="n">active_value_selector_2d</span> <span class="o">=</span> <span class="n">AnnotationElementConditionEval</span><span class="p">(</span>
<span class="linenos">433</span>        <span class="s2">&quot;gt_boxes_2d&quot;</span><span class="p">,</span>
<span class="linenos">434</span>        <span class="n">condition</span><span class="o">=</span><span class="s2">&quot;is_active = categories &gt;= 0 and is_visible&quot;</span><span class="p">,</span>
<span class="linenos">435</span>        <span class="n">remove_data_fields_used_in_condition</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">436</span>    <span class="p">)</span>
<span class="linenos">437</span>
<span class="hll"><span class="linenos">438</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">439</span>    <span class="c1"># Remove inactive elements (3D and 2D) based on the active masks (generated by the</span>
</span><span class="hll"><span class="linenos">440</span>    <span class="c1"># `AnnotationElementConditionEval` steps).</span>
</span><span class="linenos">441</span>    <span class="n">inactive_remover</span> <span class="o">=</span> <span class="n">ConditionalElementRemover</span><span class="p">(</span>
<span class="linenos">442</span>        <span class="s2">&quot;gt_boxes&quot;</span><span class="p">,</span>
<span class="linenos">443</span>        <span class="s2">&quot;is_active&quot;</span><span class="p">,</span>
<span class="linenos">444</span>        <span class="p">[</span><span class="s2">&quot;categories&quot;</span><span class="p">,</span> <span class="s2">&quot;sizes&quot;</span><span class="p">,</span> <span class="s2">&quot;rotations&quot;</span><span class="p">,</span> <span class="s2">&quot;translations&quot;</span><span class="p">,</span> <span class="s2">&quot;orientations&quot;</span><span class="p">,</span> <span class="s2">&quot;velocities&quot;</span><span class="p">],</span>
<span class="linenos">445</span>        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="linenos">446</span>        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="linenos">447</span>        <span class="kc">True</span><span class="p">,</span>
<span class="linenos">448</span>    <span class="p">)</span>
<span class="linenos">449</span>    <span class="n">inactive_remover_2d</span> <span class="o">=</span> <span class="n">ConditionalElementRemover</span><span class="p">(</span>
<span class="linenos">450</span>        <span class="s2">&quot;gt_boxes_2d&quot;</span><span class="p">,</span>
<span class="linenos">451</span>        <span class="s2">&quot;is_active&quot;</span><span class="p">,</span>
<span class="linenos">452</span>        <span class="p">[</span><span class="s2">&quot;bboxes&quot;</span><span class="p">,</span> <span class="s2">&quot;centers&quot;</span><span class="p">,</span> <span class="s2">&quot;depths&quot;</span><span class="p">,</span> <span class="s2">&quot;categories&quot;</span><span class="p">],</span>
<span class="linenos">453</span>        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="linenos">454</span>        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="linenos">455</span>        <span class="kc">True</span><span class="p">,</span>
<span class="linenos">456</span>    <span class="p">)</span>
<span class="linenos">457</span>
<span class="hll"><span class="linenos">458</span>    <span class="c1"># @NOTE Remove fields that are no longer needed for further processing.</span>
</span><span class="linenos">459</span>    <span class="n">unneded_fields_remover_post_check</span> <span class="o">=</span> <span class="n">UnneededFieldRemover</span><span class="p">(</span>
<span class="linenos">460</span>        <span class="p">[</span><span class="s2">&quot;num_lidar_points&quot;</span><span class="p">,</span> <span class="s2">&quot;num_radar_points&quot;</span><span class="p">,</span> <span class="s2">&quot;is_visible&quot;</span><span class="p">,</span> <span class="s2">&quot;is_bbox_in_range&quot;</span><span class="p">]</span>
<span class="linenos">461</span>    <span class="p">)</span>
<span class="linenos">462</span>
<span class="hll"><span class="linenos">463</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">464</span>    <span class="c1"># Crop 2D centers and bboxes to the output image size (after cropping/padding).</span>
</span><span class="hll"><span class="linenos">465</span>    <span class="c1"># First, compute tiled output dims expected downstream ...</span>
</span><span class="linenos">466</span>    <span class="n">out_img_size_x</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">affine_trafo_config</span><span class="o">.</span><span class="n">output_hw</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos">467</span>    <span class="n">out_img_size_y</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">affine_trafo_config</span><span class="o">.</span><span class="n">output_hw</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos">468</span>    <span class="n">out_img_xize_x_tiled</span> <span class="o">=</span> <span class="p">((</span><span class="n">out_img_size_x</span> <span class="o">+</span> <span class="mi">31</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">32</span>
<span class="linenos">469</span>    <span class="n">out_img_xize_y_tiled</span> <span class="o">=</span> <span class="p">((</span><span class="n">out_img_size_y</span> <span class="o">+</span> <span class="mi">31</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">32</span>
<span class="hll"><span class="linenos">470</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">471</span>    <span class="c1"># ... Then, crop bbox centers ...</span>
</span><span class="linenos">472</span>    <span class="n">bbox_cropper_centers</span> <span class="o">=</span> <span class="n">CoordinateCropper</span><span class="p">(</span>
<span class="linenos">473</span>        <span class="s2">&quot;centers&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="n">out_img_xize_x_tiled</span><span class="p">,</span> <span class="n">out_img_xize_y_tiled</span><span class="p">]</span>
<span class="linenos">474</span>    <span class="p">)</span>
<span class="hll"><span class="linenos">475</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">476</span>    <span class="c1"># ... Then, crop bboxes (2 points per bbox, same limits apply)</span>
</span><span class="linenos">477</span>    <span class="n">bbox_cropper_bboxes</span> <span class="o">=</span> <span class="n">CoordinateCropper</span><span class="p">(</span>
<span class="linenos">478</span>        <span class="s2">&quot;bboxes&quot;</span><span class="p">,</span>
<span class="linenos">479</span>        <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="linenos">480</span>        <span class="p">[</span><span class="n">out_img_xize_x_tiled</span><span class="p">,</span> <span class="n">out_img_xize_y_tiled</span><span class="p">,</span> <span class="n">out_img_xize_x_tiled</span><span class="p">,</span> <span class="n">out_img_xize_y_tiled</span><span class="p">],</span>
<span class="linenos">481</span>    <span class="p">)</span>
<span class="linenos">482</span>
<span class="hll"><span class="linenos">483</span>    <span class="c1"># @NOTE Optional BEV-space 3D bbox augmentations.</span>
</span><span class="linenos">484</span>    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">perform_3d_augmentation</span><span class="p">:</span>
<span class="linenos">485</span>        <span class="n">transformer_3d</span> <span class="o">=</span> <span class="n">BEVBBoxesTransformer3D</span><span class="p">(</span>
<span class="linenos">486</span>            <span class="s2">&quot;translations&quot;</span><span class="p">,</span>
<span class="linenos">487</span>            <span class="s2">&quot;velocities&quot;</span><span class="p">,</span>
<span class="linenos">488</span>            <span class="s2">&quot;sizes&quot;</span><span class="p">,</span>
<span class="linenos">489</span>            <span class="s2">&quot;orientations&quot;</span><span class="p">,</span>
<span class="linenos">490</span>            <span class="p">[</span><span class="s2">&quot;lidar2img&quot;</span><span class="p">,</span> <span class="s2">&quot;extr_lidar2img&quot;</span><span class="p">],</span>
<span class="linenos">491</span>            <span class="s2">&quot;lidar_ego_pose&quot;</span><span class="p">,</span>
<span class="linenos">492</span>            <span class="s2">&quot;lidar_ego_pose_inv&quot;</span><span class="p">,</span>
<span class="linenos">493</span>            <span class="n">config</span><span class="o">.</span><span class="n">bev_bboxes_trafo_config</span><span class="o">.</span><span class="n">rotation_range</span><span class="p">,</span>
<span class="linenos">494</span>            <span class="mi">2</span><span class="p">,</span>
<span class="linenos">495</span>            <span class="n">config</span><span class="o">.</span><span class="n">bev_bboxes_trafo_config</span><span class="o">.</span><span class="n">scaling_range</span><span class="p">,</span>
<span class="linenos">496</span>            <span class="n">config</span><span class="o">.</span><span class="n">bev_bboxes_trafo_config</span><span class="o">.</span><span class="n">translation_range</span><span class="p">,</span>
<span class="linenos">497</span>        <span class="p">)</span>
<span class="linenos">498</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos">499</span>        <span class="n">transformer_3d</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos">500</span>
<span class="hll"><span class="linenos">501</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">502</span>    <span class="c1"># Combine and convert intermediate outputs into a format close to StreamPETR training expectations.</span>
</span><span class="hll"><span class="linenos">503</span>    <span class="c1"># Note that:</span>
</span><span class="hll"><span class="linenos">504</span>    <span class="c1">#   - The final format cannot be exactly matched, as it contains some framework-specific containers and</span>
</span><span class="hll"><span class="linenos">505</span>    <span class="c1">#     batching conventions that cannot be represented in DALI</span>
</span><span class="hll"><span class="linenos">506</span>    <span class="c1">#   - At the same time, the format is brought as close as feasible to the final format within the DALI</span>
</span><span class="hll"><span class="linenos">507</span>    <span class="c1">#     pipeline to minimize the amount of post-processing needed outside the DALI pipeline (see</span>
</span><span class="hll"><span class="linenos">508</span>    <span class="c1">#     `dali_structured_to_torch()` in this file). This is advisable for performance reasons, as the</span>
</span><span class="hll"><span class="linenos">509</span>    <span class="c1">#     post-processing is done in the main training thread.</span>
</span><span class="hll"><span class="linenos">510</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">511</span>    <span class="c1"># Also, please note that this step is very specific to the StreamPETR training use-case. Therefore,</span>
</span><span class="hll"><span class="linenos">512</span>    <span class="c1"># it is part of the example, and not included in the core DALI pipeline package. You can find it in</span>
</span><span class="hll"><span class="linenos">513</span>    <span class="c1"># in the repository under</span>
</span><span class="hll"><span class="linenos">514</span>    <span class="c1"># `packages/dali_pipeline_framework/examples/pipeline_setup/additional_impl/processing_steps/stream_petr_data_combiner.py`.</span>
</span><span class="linenos">515</span>    <span class="n">training_data_format_converter</span> <span class="o">=</span> <span class="n">StreamPETRDataCombiner</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">516</span>
<span class="hll"><span class="linenos">517</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">518</span>    <span class="c1"># Apply padding so variable-length arrays become uniform across the batch. Note that only specific fields</span>
</span><span class="hll"><span class="linenos">519</span>    <span class="c1"># are padded. This is similar to the 2D object detection example, but here, the fields are defined by</span>
</span><span class="hll"><span class="linenos">520</span>    <span class="c1"># name (instead of specifying a root field, and padding everything it contains).</span>
</span><span class="linenos">521</span>    <span class="n">padding_to_uniform</span> <span class="o">=</span> <span class="n">PaddingToUniform</span><span class="p">(</span>
<span class="linenos">522</span>        <span class="n">field_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gt_bboxes_3d&quot;</span><span class="p">,</span> <span class="s2">&quot;gt_labels_3d&quot;</span><span class="p">,</span> <span class="s2">&quot;gt_bboxes&quot;</span><span class="p">,</span> <span class="s2">&quot;depths&quot;</span><span class="p">,</span> <span class="s2">&quot;centers2d&quot;</span><span class="p">,</span> <span class="s2">&quot;gt_labels&quot;</span><span class="p">]</span>
<span class="linenos">523</span>    <span class="p">)</span>
<span class="linenos">524</span>
<span class="hll"><span class="linenos">525</span>    <span class="c1"># @NOTE Define the pipeline steps sequence; `None` entries are ignored.</span>
</span><span class="linenos">526</span>    <span class="n">pre_processing_steps</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos">527</span>        <span class="n">decoder</span><span class="p">,</span>
<span class="linenos">528</span>        <span class="n">image_trafo</span><span class="p">,</span>
<span class="linenos">529</span>        <span class="n">image_padder</span><span class="p">,</span>
<span class="linenos">530</span>        <span class="n">normalizer</span><span class="p">,</span>
<span class="linenos">531</span>        <span class="n">visible_bbox_selector</span><span class="p">,</span>
<span class="linenos">532</span>        <span class="n">bbox_inside_range_selector</span><span class="p">,</span>
<span class="linenos">533</span>        <span class="n">active_value_selector</span><span class="p">,</span>
<span class="linenos">534</span>        <span class="n">active_value_selector_2d</span><span class="p">,</span>
<span class="linenos">535</span>        <span class="n">inactive_remover</span><span class="p">,</span>
<span class="linenos">536</span>        <span class="n">inactive_remover_2d</span><span class="p">,</span>
<span class="linenos">537</span>        <span class="n">unneded_fields_remover_post_check</span><span class="p">,</span>
<span class="linenos">538</span>        <span class="n">bbox_cropper_centers</span><span class="p">,</span>
<span class="linenos">539</span>        <span class="n">bbox_cropper_bboxes</span><span class="p">,</span>
<span class="linenos">540</span>        <span class="n">transformer_3d</span><span class="p">,</span>
<span class="linenos">541</span>        <span class="n">training_data_format_converter</span><span class="p">,</span>
<span class="linenos">542</span>        <span class="n">padding_to_uniform</span><span class="p">,</span>
<span class="linenos">543</span>    <span class="p">]</span>
<span class="linenos">544</span>
</pre></div>
</div>
</div>
</section>
<section id="pipeline-definition-output-data-format">
<h3>Pipeline Definition &amp; Output Data Format<a class="headerlink" href="#pipeline-definition-output-data-format" title="Link to this heading"></a></h3>
<p>Wiring the input implementation with the steps and capturing the output data structure blueprint.
For details on the output blueprint, refer back to the <a class="reference internal" href="../2d_object_detection/pipeline_setup.html"><span class="doc">2D Object Detection Pipeline Setup</span></a>.</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/stream_petr_pipeline.py</span><a class="headerlink" href="#id3" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">545</span>    <span class="c1"># ===== Pipeline definition &amp; Output data format =====</span>
<span class="hll"><span class="linenos">546</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">547</span>    <span class="c1"># Define the pipeline by wiring the input implementation and the pre-processing steps.</span>
</span><span class="hll"><span class="linenos">548</span>    <span class="c1">#</span>
</span><span class="hll"><span class="linenos">549</span>    <span class="c1"># IMPORTANT: Note how `check_data_format` is set to `False` here. This is done to avoid the overhead of</span>
</span><span class="hll"><span class="linenos">550</span>    <span class="c1"># checking the data format during pipeline execution. During development, it is recommended to set it</span>
</span><span class="hll"><span class="linenos">551</span>    <span class="c1"># to `True` to catch potential issues early, and later set it to `False` to avoid the overhead in</span>
</span><span class="hll"><span class="linenos">552</span>    <span class="c1"># production.</span>
</span><span class="linenos">553</span>    <span class="n">pipeline_def</span> <span class="o">=</span> <span class="n">PipelineDefinition</span><span class="p">(</span>
<span class="linenos">554</span>        <span class="n">input_impl</span><span class="p">,</span> <span class="n">pre_processing_steps</span><span class="p">,</span> <span class="n">check_data_format</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">print_sample_data_group_format</span><span class="o">=</span><span class="kc">True</span>
<span class="linenos">555</span>    <span class="p">)</span>
<span class="linenos">556</span>
<span class="hll"><span class="linenos">557</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">558</span>    <span class="c1"># Check and capture the output data structure blueprint. See the 2D object detection example for an</span>
</span><span class="hll"><span class="linenos">559</span>    <span class="c1"># in-depth description.</span>
</span><span class="linenos">560</span>    <span class="n">res_data_setup</span> <span class="o">=</span> <span class="n">pipeline_def</span><span class="o">.</span><span class="n">check_and_get_output_data_structure</span><span class="p">()</span>
<span class="linenos">561</span>
</pre></div>
</div>
</div>
</section>
<section id="create-and-build-the-dali-pipeline">
<h3>Create and Build the DALI Pipeline<a class="headerlink" href="#create-and-build-the-dali-pipeline" title="Link to this heading"></a></h3>
<p>Seed setup for augmentation reproducibility, pipeline creation, and build. See the
<a class="reference internal" href="../2d_object_detection/pipeline_setup.html"><span class="doc">2D Object Detection Pipeline Setup</span></a> for more background on these steps.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/stream_petr_pipeline.py</span><a class="headerlink" href="#id4" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">562</span>    <span class="c1"># ===== Create DALI pipeline =====</span>
<span class="hll"><span class="linenos">563</span>    <span class="c1"># @NOTE:</span>
</span><span class="hll"><span class="linenos">564</span>    <span class="c1"># Seed for augmentation reproducibility (rank-specific). Please also see the 2D object detection example</span>
</span><span class="hll"><span class="linenos">565</span>    <span class="c1"># for more details.</span>
</span><span class="linenos">566</span>    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">use_reproducible_seed</span><span class="p">:</span>
<span class="linenos">567</span>        <span class="n">seed</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span>
<span class="linenos">568</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos">569</span>        <span class="n">seed</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="linenos">570</span>
<span class="linenos">571</span>    <span class="c1"># Start measuring creation time</span>
<span class="linenos">572</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">start_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_create&quot;</span><span class="p">)</span>
<span class="hll"><span class="linenos">573</span>    <span class="c1"># @NOTE Obtain the actual DALI Pipeline object (see DALI getting started docs).</span>
</span><span class="linenos">574</span>    <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline_def</span><span class="o">.</span><span class="n">get_dali_pipeline</span><span class="p">(</span>
<span class="linenos">575</span>        <span class="n">enable_conditionals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos">576</span>        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span class="linenos">577</span>        <span class="n">prefetch_queue_depth</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">pipeline_config</span><span class="o">.</span><span class="n">prefetch_queue_depth</span><span class="p">,</span>
<span class="linenos">578</span>        <span class="n">py_num_workers</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">pipeline_config</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
<span class="linenos">579</span>        <span class="n">py_start_method</span><span class="o">=</span><span class="s2">&quot;spawn&quot;</span><span class="p">,</span>
<span class="linenos">580</span>        <span class="n">num_threads</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">pipeline_config</span><span class="o">.</span><span class="n">num_threads</span><span class="p">,</span>
<span class="linenos">581</span>        <span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">,</span>
<span class="linenos">582</span>        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
<span class="linenos">583</span>    <span class="p">)</span>
<span class="linenos">584</span>    <span class="c1"># End measuring creation time</span>
<span class="linenos">585</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">end_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_create&quot;</span><span class="p">)</span>
<span class="linenos">586</span>
<span class="linenos">587</span>    <span class="c1"># Start measuring build time</span>
<span class="linenos">588</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">start_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_build&quot;</span><span class="p">)</span>
<span class="linenos">589</span>
<span class="linenos">590</span>    <span class="c1"># For details on preparing the pipeline see:</span>
<span class="linenos">591</span>    <span class="c1"># case spawn:</span>
<span class="linenos">592</span>    <span class="c1"># https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/general/data_loading/parallel_external_source.html</span>
<span class="linenos">593</span>    <span class="c1"># case fork:</span>
<span class="linenos">594</span>    <span class="c1"># https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/general/data_loading/parallel_external_source_fork.html</span>
<span class="linenos">595</span>    <span class="n">pipe</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="linenos">596</span>    <span class="c1"># End measuring build time</span>
<span class="linenos">597</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">end_one_time_measurement</span><span class="p">(</span><span class="s2">&quot;pipe_build&quot;</span><span class="p">)</span>
<span class="linenos">598</span>
</pre></div>
</div>
</div>
</section>
<section id="wrap-as-structured-iterator">
<h3>Wrap as Structured Iterator<a class="headerlink" href="#wrap-as-structured-iterator" title="Link to this heading"></a></h3>
<p>The pipeline is wrapped as a <code class="docutils literal notranslate"><span class="pre">DALIStructuredOutputIterator</span></code>. A post-processing function aligns the
output format to the structures expected by StreamPETR training.</p>
<p>For detail on the post-processing function, see <a class="reference internal" href="custom_post_processing.html"><span class="doc">Custom Post-Processing</span></a>.</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">packages/dali_pipeline_framework/examples/pipeline_setup/stream_petr_pipeline.py</span><a class="headerlink" href="#id5" title="Link to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">599</span>    <span class="c1"># ===== Wrap as iterator =====</span>
<span class="hll"><span class="linenos">600</span>    <span class="c1"># @NOTE</span>
</span><span class="hll"><span class="linenos">601</span>    <span class="c1"># Wrap pipeline as a DALIStructuredOutputIterator (drop-in replacement for a PyTorch DataLoader).</span>
</span><span class="hll"><span class="linenos">602</span>    <span class="c1"># Setup the post-processing function to align the data format with StreamPETR training expectations.</span>
</span><span class="hll"><span class="linenos">603</span>    <span class="c1"># See the 2D object detection example for more details.</span>
</span><span class="linenos">604</span>    <span class="n">dali_structured_to_torch_used</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">dali_structured_to_torch</span><span class="p">,</span> <span class="n">for_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="hll"><span class="linenos">605</span>    <span class="c1"># @NOTE: Set up the iterator</span>
</span><span class="linenos">606</span>    <span class="n">res_iterator</span> <span class="o">=</span> <span class="n">DALIStructuredOutputIterator</span><span class="o">.</span><span class="n">CreateAsDataLoaderObject</span><span class="p">(</span>
<span class="linenos">607</span>        <span class="n">num_batches_in_epoch</span><span class="p">,</span> <span class="n">pipe</span><span class="p">,</span> <span class="n">res_data_setup</span><span class="p">,</span> <span class="n">post_process_func</span><span class="o">=</span><span class="n">dali_structured_to_torch_used</span>
<span class="linenos">608</span>    <span class="p">)</span>
<span class="linenos">609</span>
<span class="linenos">610</span>    <span class="c1"># Print measured times</span>
<span class="linenos">611</span>    <span class="n">stopwatch</span><span class="o">.</span><span class="n">print_eval_times</span><span class="p">()</span>
<span class="linenos">612</span>
<span class="linenos">613</span>    <span class="c1"># Return the wrapped pipeline.</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="StreamPETR Pipeline" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="custom_processing_step.html" class="btn btn-neutral float-right" title="Custom Processing Step: StreamPETRDataCombiner" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>